{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24c4d602",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required nltk libraries\n",
    "import nltk\n",
    "from nltk import sent_tokenize\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9662b374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            Responses:\n",
      "0    Single cask Aberfeldy bottlings are very few a...\n",
      "1    From a sherry cask. Bright and lively. Quite f...\n",
      "2    Similar in flavor to the Aberfeldy 12 reviewed...\n",
      "3    A prime component in Dewar’s blended scotch. T...\n",
      "4    Independent releases of the Perthshire single ...\n",
      "..                                                 ...\n",
      "145  A peculiar Auchentoshan. The Bordeaux wine dom...\n",
      "146  This whisky comes from two bourbon casks, prod...\n",
      "147  Poor old Auchroisk. Not only couldn’t anyone p...\n",
      "148  The original Singleton, seemingly discarded as...\n",
      "149  Here is Auchroisk at its more lifted and clean...\n",
      "\n",
      "[150 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# loading our corpus Negative Reviews\n",
    "import os\n",
    "os.getcwd()\n",
    "test_set = pd.read_csv(r'C:\\\\Users\\\\HP\\\\OneDrive\\\\Desktop\\\\Grad School\\\\IST718 Big Data\\\\Semester Project\\\\Scotch_Reviews.csv')\n",
    "print(test_set[:150])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5df5a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
      "0    5.703060e+17           neutral                        1.0000   \n",
      "1    5.703010e+17          positive                        0.3486   \n",
      "2    5.703010e+17           neutral                        0.6837   \n",
      "3    5.703010e+17          negative                        1.0000   \n",
      "4    5.703010e+17          negative                        1.0000   \n",
      "..            ...               ...                           ...   \n",
      "145  5.696100e+17          negative                        1.0000   \n",
      "146  5.696080e+17          negative                        0.6790   \n",
      "147  5.696000e+17          positive                        1.0000   \n",
      "148  5.695960e+17          positive                        1.0000   \n",
      "149  5.695960e+17          negative                        1.0000   \n",
      "\n",
      "              negativereason  negativereason_confidence         airline  \\\n",
      "0                        NaN                        NaN  Virgin America   \n",
      "1                        NaN                     0.0000  Virgin America   \n",
      "2                        NaN                        NaN  Virgin America   \n",
      "3                 Bad Flight                     0.7033  Virgin America   \n",
      "4                 Can't Tell                     1.0000  Virgin America   \n",
      "..                       ...                        ...             ...   \n",
      "145         Cancelled Flight                     1.0000  Virgin America   \n",
      "146  Flight Booking Problems                     0.3684  Virgin America   \n",
      "147                      NaN                        NaN  Virgin America   \n",
      "148                      NaN                        NaN  Virgin America   \n",
      "149          Damaged Luggage                     0.6501  Virgin America   \n",
      "\n",
      "    airline_sentiment_gold            name negativereason_gold  retweet_count  \\\n",
      "0                      NaN         cairdin                 NaN              0   \n",
      "1                      NaN        jnardino                 NaN              0   \n",
      "2                      NaN      yvonnalynn                 NaN              0   \n",
      "3                      NaN        jnardino                 NaN              0   \n",
      "4                      NaN        jnardino                 NaN              0   \n",
      "..                     ...             ...                 ...            ...   \n",
      "145                    NaN       mlorenzen                 NaN              0   \n",
      "146                    NaN  Tyler_Starrine                 NaN              0   \n",
      "147                    NaN   jessicajaymes                 NaN              2   \n",
      "148                    NaN     livingfitly                 NaN              0   \n",
      "149                    NaN       khartline                 NaN              0   \n",
      "\n",
      "                                                  text  \\\n",
      "0                  @VirginAmerica What @dhepburn said.   \n",
      "1    @VirginAmerica plus you've added commercials t...   \n",
      "2    @VirginAmerica I didn't today... Must mean I n...   \n",
      "3    @VirginAmerica it's really aggressive to blast...   \n",
      "4    @VirginAmerica and it's a really big bad thing...   \n",
      "..                                                 ...   \n",
      "145  @VirginAmerica I paid the premium to fly you a...   \n",
      "146  @VirginAmerica question: is it not possible to...   \n",
      "147  Always have it together!!! You're welcome! RT ...   \n",
      "148  @virginamerica #flight home to #dc #sunset #gl...   \n",
      "149  .@VirginAmerica I don't understand why you nee...   \n",
      "\n",
      "                      tweet_coord    tweet_created  \\\n",
      "0                             NaN  2/24/2015 11:35   \n",
      "1                             NaN  2/24/2015 11:15   \n",
      "2                             NaN  2/24/2015 11:15   \n",
      "3                             NaN  2/24/2015 11:15   \n",
      "4                             NaN  2/24/2015 11:14   \n",
      "..                            ...              ...   \n",
      "145                           NaN  2/22/2015 13:29   \n",
      "146                           NaN  2/22/2015 13:23   \n",
      "147  [33.94652852, -118.40766257]  2/22/2015 12:49   \n",
      "148                           NaN  2/22/2015 12:35   \n",
      "149                           NaN  2/22/2015 12:34   \n",
      "\n",
      "                   tweet_location               user_timezone  \n",
      "0                             NaN  Eastern Time (US & Canada)  \n",
      "1                             NaN  Pacific Time (US & Canada)  \n",
      "2                       Lets Play  Central Time (US & Canada)  \n",
      "3                             NaN  Pacific Time (US & Canada)  \n",
      "4                             NaN  Pacific Time (US & Canada)  \n",
      "..                            ...                         ...  \n",
      "145  iPhone: 29.741360,-90.131523  Pacific Time (US & Canada)  \n",
      "146                   Los Angeles  Pacific Time (US & Canada)  \n",
      "147         hollywood, california  Pacific Time (US & Canada)  \n",
      "148                Washington, DC  Eastern Time (US & Canada)  \n",
      "149                     Las Vegas  Pacific Time (US & Canada)  \n",
      "\n",
      "[150 rows x 15 columns]\n"
     ]
    }
   ],
   "source": [
    "#using the Airline Services dataset for training on sentiment polarity\n",
    "train_dataset = pd.read_csv(r'C:\\\\Users\\\\HP\\\\OneDrive\\\\Desktop\\\\Grad School\\\\IST 664 NLP\\\\train_tweets_airlines1.csv')\n",
    "print(train_dataset[:150])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab733d9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8456"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#displaying the dataset using pandas\n",
    "display(len(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2dd1ab04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since this is social media data, we will have to add a few extra preprocessing steps\n",
    "# First, let's remove  @ and # (Twitter platform affordances) from the training data\n",
    "# We'll use regular expressions for that, creating a Function that we can use to pass the data through\n",
    "# NOTE: you could add more regexes to clean noisy characters such as emoticons, numbers, etc\n",
    "def remove_at(x):\n",
    "    x = str(x).replace('@', '')\n",
    "    x = str(x).replace('#', '')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39b03b03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8456"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#applying the clearning function and visualizing the result\n",
    "train_dataset['text'] = train_dataset['text'].apply(lambda x: remove_at(x))\n",
    "display(len(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9785313a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8456"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset['text'] = train_dataset['text'].apply(lambda x: remove_at(x))\n",
    "display(len(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bebc349",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                    VirginAmerica What dhepburn said.\n",
       "1    VirginAmerica plus you've added commercials to...\n",
       "2    VirginAmerica I didn't today... Must mean I ne...\n",
       "3    VirginAmerica it's really aggressive to blast ...\n",
       "4    VirginAmerica and it's a really big bad thing ...\n",
       "Name: text, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train_dataset['text'].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f27c478a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8456"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tokenizing using RegexTokenizer for tokenizing using specific regular expressions\n",
    "# in our case, we eliminate Twitter's noise by picking up only alphabets and numbers\n",
    "# indicated by the 'w', the regex alias for 'word'\n",
    "   \n",
    "import nltk\n",
    "    \n",
    "tokenizer = nltk.RegexpTokenizer('\\\\w+')\n",
    "doc = train_dataset['text'].apply(lambda x : tokenizer.tokenize(x))\n",
    "display(len(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5247644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                [VirginAmerica, What, dhepburn, said]\n",
       "1    [VirginAmerica, plus, you, ve, added, commerci...\n",
       "2    [VirginAmerica, I, didn, t, today, Must, mean,...\n",
       "3    [VirginAmerica, it, s, really, aggressive, to,...\n",
       "4    [VirginAmerica, and, it, s, a, really, big, ba...\n",
       "Name: text, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(doc.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d87cf540",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPLORATORY ANAYSIS\n",
    "#Checking if the dataset is balanced\n",
    "#extracting types of labels from the 'airline_sentiment' column in the dataset\n",
    "PosSentences = train_dataset[train_dataset['airline_sentiment'] == 'positive']\n",
    "NegSentences = train_dataset[train_dataset['airline_sentiment'] == 'negative']\n",
    "NeuSentences = train_dataset[train_dataset['airline_sentiment'] == 'neutral']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb787c3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negative</td>\n",
       "      <td>2994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>3099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>positive</td>\n",
       "      <td>2363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline_sentiment  counts\n",
       "0          negative    2994\n",
       "1           neutral    3099\n",
       "2          positive    2363"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#grouping all labels to find out the count for each group\n",
    "label_groups = train_dataset.groupby('airline_sentiment').size().reset_index(name='counts')\n",
    "display(label_groups.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4905a6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizing label group data within training dataset\n",
    "# NOTE that the dataset is unbalanced\n",
    "# please come up with strategies to balance this dataset\n",
    "# if not, explain how that affect your results\n",
    "# if using unbalanced dataset, please provide MicroAverage evaluation scores from your classifier\n",
    "   \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe82148e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "ax = sns.barplot(x=\"airline_sentiment\", y=\"counts\", data=label_groups)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=0)\n",
    "ax.set_title(label=\"Sentiment Distribution\")\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2fc99d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BEGGINING TO WORK ON THE CLASSIFICATION TASK\n",
    "# extracting the tweet message and its asigned sentiment label\n",
    "# we do this by creating a Python list\n",
    "# our list will have the tweet's tokens and corresponding sentiments\n",
    "   \n",
    "# opening a list to store our data\n",
    "docs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "53a3fab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterating over the dataset and extracting the information sought\n",
    "for i in range(0, len(train_dataset['airline_sentiment'])):\n",
    "    # appending the info to the list\n",
    "    docs.append((doc[i], train_dataset['airline_sentiment'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "03e9e1e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['VirginAmerica', 'What', 'dhepburn', 'said'], 'neutral')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#printing the output for validation\n",
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e510309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dataset is sorted by sentiment label\n",
    "# so we need to randomize it to avoid sampling biases \n",
    "   \n",
    "#importing the random library\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8186faff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffling the documents\n",
    "random.shuffle(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0296faa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining set of words that will be used for features\n",
    "#we'll find the 2000 most common words and used them as an important feature of the whole corpus\n",
    "   \n",
    "all_words = [word for (sentance,category) in docs for word in sentance]\n",
    "top_words = nltk.FreqDist(all_words)\n",
    "most_common_words = top_words.most_common(2000)\n",
    "word_features = [word for (word,count) in most_common_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f2983316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13306"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking if we have the 2000 words we need\n",
    "len(set(all_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a095326",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################now we will use that list of most frequent words in the entire corpus\n",
    "#to iterate over each sentence and check if any of those words are present\n",
    "#in that way, we will see if this unigram corpus feature is present on that particular sentence\n",
    "#using Boolean logic that matches values and returns 'True' or 'False'\n",
    "#we do this by defining a Python \\\"function,\\\" i.e.a piece of code writen to be reused\n",
    "def document_features(document, word_features):\n",
    "    document_words = set(document)\n",
    "    #we open a Pytnon dictionary instead of a list\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "    #checking if the word from word_features matches a word in the document\n",
    "        features['contains({})'.format(word)] = (word in document_words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9840e91e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'contains(to)': False,\n",
       "  'contains(united)': False,\n",
       "  'contains(I)': False,\n",
       "  'contains(the)': False,\n",
       "  'contains(you)': False,\n",
       "  'contains(a)': True,\n",
       "  'contains(for)': False,\n",
       "  'contains(t)': False,\n",
       "  'contains(on)': False,\n",
       "  'contains(and)': True,\n",
       "  'contains(my)': False,\n",
       "  'contains(flight)': True,\n",
       "  'contains(in)': False,\n",
       "  'contains(SouthwestAir)': True,\n",
       "  'contains(JetBlue)': False,\n",
       "  'contains(is)': False,\n",
       "  'contains(it)': False,\n",
       "  'contains(of)': False,\n",
       "  'contains(me)': False,\n",
       "  'contains(co)': False,\n",
       "  'contains(s)': False,\n",
       "  'contains(http)': False,\n",
       "  'contains(AmericanAir)': False,\n",
       "  'contains(that)': False,\n",
       "  'contains(with)': True,\n",
       "  'contains(have)': False,\n",
       "  'contains(your)': False,\n",
       "  'contains(was)': False,\n",
       "  'contains(at)': False,\n",
       "  'contains(can)': False,\n",
       "  'contains(from)': False,\n",
       "  'contains(USAirways)': False,\n",
       "  'contains(be)': False,\n",
       "  'contains(this)': False,\n",
       "  'contains(get)': False,\n",
       "  'contains(not)': False,\n",
       "  'contains(are)': True,\n",
       "  'contains(but)': False,\n",
       "  'contains(VirginAmerica)': False,\n",
       "  'contains(we)': False,\n",
       "  'contains(no)': False,\n",
       "  'contains(so)': False,\n",
       "  'contains(do)': False,\n",
       "  'contains(service)': False,\n",
       "  'contains(Thanks)': False,\n",
       "  'contains(will)': False,\n",
       "  'contains(thanks)': True,\n",
       "  'contains(just)': False,\n",
       "  'contains(an)': False,\n",
       "  'contains(now)': False,\n",
       "  'contains(time)': False,\n",
       "  'contains(m)': False,\n",
       "  'contains(out)': False,\n",
       "  'contains(help)': False,\n",
       "  'contains(flights)': False,\n",
       "  'contains(Cancelled)': False,\n",
       "  'contains(Flight)': False,\n",
       "  'contains(2)': True,\n",
       "  'contains(amp)': False,\n",
       "  'contains(there)': False,\n",
       "  'contains(up)': False,\n",
       "  'contains(customer)': False,\n",
       "  'contains(all)': False,\n",
       "  'contains(United)': False,\n",
       "  'contains(would)': False,\n",
       "  'contains(they)': False,\n",
       "  'contains(when)': False,\n",
       "  'contains(Thank)': False,\n",
       "  'contains(if)': False,\n",
       "  'contains(plane)': False,\n",
       "  'contains(what)': False,\n",
       "  'contains(been)': False,\n",
       "  'contains(as)': False,\n",
       "  'contains(our)': False,\n",
       "  'contains(one)': False,\n",
       "  'contains(bag)': False,\n",
       "  'contains(about)': False,\n",
       "  'contains(or)': False,\n",
       "  'contains(like)': False,\n",
       "  'contains(thank)': False,\n",
       "  'contains(us)': False,\n",
       "  'contains(back)': False,\n",
       "  'contains(need)': False,\n",
       "  'contains(gate)': False,\n",
       "  'contains(how)': False,\n",
       "  'contains(know)': False,\n",
       "  'contains(today)': False,\n",
       "  'contains(great)': True,\n",
       "  'contains(got)': False,\n",
       "  'contains(please)': False,\n",
       "  'contains(has)': False,\n",
       "  'contains(had)': True,\n",
       "  'contains(delayed)': False,\n",
       "  'contains(You)': False,\n",
       "  'contains(airline)': False,\n",
       "  'contains(fly)': False,\n",
       "  'contains(still)': False,\n",
       "  'contains(any)': False,\n",
       "  'contains(am)': False,\n",
       "  'contains(guys)': True,\n",
       "  'contains(re)': False,\n",
       "  'contains(way)': False,\n",
       "  'contains(DM)': False,\n",
       "  'contains(by)': False,\n",
       "  'contains(flying)': False,\n",
       "  'contains(why)': False,\n",
       "  'contains(3)': False,\n",
       "  'contains(after)': False,\n",
       "  'contains(ve)': False,\n",
       "  'contains(don)': False,\n",
       "  'contains(Late)': False,\n",
       "  'contains(check)': False,\n",
       "  'contains(hours)': False,\n",
       "  'contains(more)': False,\n",
       "  'contains(Can)': False,\n",
       "  'contains(1)': False,\n",
       "  'contains(ll)': False,\n",
       "  'contains(We)': False,\n",
       "  'contains(It)': False,\n",
       "  'contains(go)': False,\n",
       "  'contains(again)': False,\n",
       "  'contains(tomorrow)': False,\n",
       "  'contains(make)': False,\n",
       "  'contains(i)': False,\n",
       "  'contains(did)': False,\n",
       "  'contains(see)': False,\n",
       "  'contains(good)': False,\n",
       "  'contains(airport)': False,\n",
       "  'contains(day)': False,\n",
       "  'contains(change)': False,\n",
       "  'contains(last)': False,\n",
       "  'contains(much)': False,\n",
       "  'contains(seat)': False,\n",
       "  'contains(Flightled)': False,\n",
       "  'contains(hour)': False,\n",
       "  'contains(love)': False,\n",
       "  'contains(were)': False,\n",
       "  'contains(home)': False,\n",
       "  'contains(first)': False,\n",
       "  'contains(should)': False,\n",
       "  'contains(crew)': False,\n",
       "  'contains(over)': False,\n",
       "  'contains(ticket)': False,\n",
       "  'contains(new)': False,\n",
       "  'contains(only)': False,\n",
       "  'contains(going)': False,\n",
       "  'contains(then)': False,\n",
       "  'contains(Our)': False,\n",
       "  'contains(number)': False,\n",
       "  'contains(people)': False,\n",
       "  'contains(email)': False,\n",
       "  'contains(here)': False,\n",
       "  'contains(take)': False,\n",
       "  'contains(Just)': False,\n",
       "  'contains(off)': False,\n",
       "  'contains(u)': False,\n",
       "  'contains(4)': False,\n",
       "  'contains(phone)': False,\n",
       "  'contains(bags)': False,\n",
       "  'contains(them)': False,\n",
       "  'contains(weather)': False,\n",
       "  'contains(wait)': False,\n",
       "  'contains(sent)': False,\n",
       "  'contains(next)': False,\n",
       "  'contains(trip)': False,\n",
       "  'contains(travel)': False,\n",
       "  'contains(who)': False,\n",
       "  'contains(because)': False,\n",
       "  'contains(trying)': False,\n",
       "  'contains(call)': False,\n",
       "  'contains(delay)': False,\n",
       "  'contains(fleet)': False,\n",
       "  'contains(waiting)': False,\n",
       "  'contains(The)': False,\n",
       "  'contains(want)': False,\n",
       "  'contains(fleek)': False,\n",
       "  'contains(best)': False,\n",
       "  'contains(too)': False,\n",
       "  'contains(getting)': False,\n",
       "  'contains(What)': False,\n",
       "  'contains(could)': False,\n",
       "  'contains(response)': False,\n",
       "  'contains(really)': False,\n",
       "  'contains(work)': False,\n",
       "  'contains(very)': False,\n",
       "  'contains(even)': False,\n",
       "  'contains(seats)': False,\n",
       "  'contains(made)': False,\n",
       "  'contains(5)': False,\n",
       "  'contains(staff)': False,\n",
       "  'contains(right)': False,\n",
       "  'contains(yes)': False,\n",
       "  'contains(How)': False,\n",
       "  'contains(w)': False,\n",
       "  'contains(boarding)': False,\n",
       "  'contains(never)': False,\n",
       "  'contains(No)': False,\n",
       "  'contains(lost)': False,\n",
       "  'contains(sure)': False,\n",
       "  'contains(booked)': False,\n",
       "  'contains(Is)': False,\n",
       "  'contains(through)': False,\n",
       "  'contains(baggage)': False,\n",
       "  'contains(she)': False,\n",
       "  'contains(agent)': False,\n",
       "  'contains(before)': False,\n",
       "  'contains(their)': False,\n",
       "  'contains(than)': False,\n",
       "  'contains(My)': False,\n",
       "  'contains(d)': False,\n",
       "  'contains(due)': False,\n",
       "  'contains(let)': False,\n",
       "  'contains(luggage)': False,\n",
       "  'contains(tonight)': False,\n",
       "  'contains(another)': False,\n",
       "  'contains(other)': False,\n",
       "  'contains(SFO)': False,\n",
       "  'contains(ever)': False,\n",
       "  'contains(follow)': False,\n",
       "  'contains(her)': False,\n",
       "  'contains(some)': False,\n",
       "  'contains(two)': False,\n",
       "  'contains(passengers)': False,\n",
       "  'contains(told)': False,\n",
       "  'contains(experience)': False,\n",
       "  'contains(morning)': False,\n",
       "  'contains(hold)': False,\n",
       "  'contains(left)': False,\n",
       "  'contains(minutes)': False,\n",
       "  'contains(ORD)': False,\n",
       "  'contains(better)': False,\n",
       "  'contains(book)': False,\n",
       "  'contains(into)': False,\n",
       "  'contains(This)': False,\n",
       "  'contains(Please)': False,\n",
       "  'contains(use)': False,\n",
       "  'contains(didn)': False,\n",
       "  'contains(think)': False,\n",
       "  'contains(days)': False,\n",
       "  'contains(LAX)': False,\n",
       "  'contains(does)': False,\n",
       "  'contains(tickets)': False,\n",
       "  'contains(someone)': False,\n",
       "  'contains(long)': False,\n",
       "  'contains(awesome)': False,\n",
       "  'contains(Your)': False,\n",
       "  'contains(10)': False,\n",
       "  'contains(That)': False,\n",
       "  'contains(A)': False,\n",
       "  'contains(Booking)': False,\n",
       "  'contains(give)': False,\n",
       "  'contains(same)': False,\n",
       "  'contains(Problems)': False,\n",
       "  'contains(class)': False,\n",
       "  'contains(being)': False,\n",
       "  'contains(already)': False,\n",
       "  'contains(free)': False,\n",
       "  'contains(reservation)': False,\n",
       "  'contains(where)': False,\n",
       "  'contains(he)': False,\n",
       "  'contains(miss)': False,\n",
       "  'contains(care)': False,\n",
       "  'contains(via)': False,\n",
       "  'contains(well)': False,\n",
       "  'contains(amazing)': False,\n",
       "  'contains(Not)': False,\n",
       "  'contains(JFK)': False,\n",
       "  'contains(connection)': False,\n",
       "  'contains(EWR)': False,\n",
       "  'contains(night)': False,\n",
       "  'contains(find)': False,\n",
       "  'contains(They)': False,\n",
       "  'contains(hope)': False,\n",
       "  'contains(down)': False,\n",
       "  'contains(If)': False,\n",
       "  'contains(AA)': False,\n",
       "  'contains(issue)': False,\n",
       "  'contains(6)': False,\n",
       "  'contains(checked)': False,\n",
       "  'contains(min)': False,\n",
       "  'contains(RT)': False,\n",
       "  'contains(website)': False,\n",
       "  'contains(miles)': False,\n",
       "  'contains(Will)': False,\n",
       "  'contains(delays)': False,\n",
       "  'contains(refund)': False,\n",
       "  'contains(online)': False,\n",
       "  'contains(week)': False,\n",
       "  'contains(30)': False,\n",
       "  'contains(appreciate)': False,\n",
       "  'contains(yet)': False,\n",
       "  'contains(Why)': False,\n",
       "  'contains(status)': False,\n",
       "  'contains(said)': False,\n",
       "  'contains(able)': False,\n",
       "  'contains(But)': False,\n",
       "  'contains(DestinationDragons)': False,\n",
       "  'contains(upgrade)': False,\n",
       "  'contains(times)': False,\n",
       "  'contains(Any)': False,\n",
       "  'contains(its)': False,\n",
       "  'contains(airlines)': False,\n",
       "  'contains(Flighted)': False,\n",
       "  'contains(done)': False,\n",
       "  'contains(tell)': False,\n",
       "  'contains(board)': False,\n",
       "  'contains(customers)': False,\n",
       "  'contains(name)': False,\n",
       "  'contains(team)': False,\n",
       "  'contains(bad)': False,\n",
       "  'contains(Do)': False,\n",
       "  'contains(won)': False,\n",
       "  'contains(helpful)': False,\n",
       "  'contains(Denver)': False,\n",
       "  'contains(ago)': False,\n",
       "  'contains(15)': False,\n",
       "  'contains(nice)': False,\n",
       "  'contains(info)': False,\n",
       "  'contains(US)': False,\n",
       "  'contains(sitting)': False,\n",
       "  'contains(since)': False,\n",
       "  'contains(8)': False,\n",
       "  'contains(20)': False,\n",
       "  'contains(business)': False,\n",
       "  'contains(1st)': False,\n",
       "  'contains(year)': False,\n",
       "  'contains(Chicago)': False,\n",
       "  'contains(though)': False,\n",
       "  'contains(And)': False,\n",
       "  'contains(agents)': False,\n",
       "  'contains(doesn)': False,\n",
       "  'contains(7)': False,\n",
       "  'contains(Great)': False,\n",
       "  'contains(So)': False,\n",
       "  'contains(issues)': False,\n",
       "  'contains(put)': False,\n",
       "  'contains(wifi)': False,\n",
       "  'contains(anything)': False,\n",
       "  'contains(finally)': False,\n",
       "  'contains(early)': False,\n",
       "  'contains(hrs)': False,\n",
       "  'contains(look)': False,\n",
       "  'contains(chance)': False,\n",
       "  'contains(Newark)': False,\n",
       "  'contains(always)': False,\n",
       "  'contains(say)': False,\n",
       "  'contains(show)': False,\n",
       "  'contains(job)': False,\n",
       "  'contains(IAD)': False,\n",
       "  'contains(DFW)': False,\n",
       "  'contains(worst)': False,\n",
       "  'contains(those)': False,\n",
       "  'contains(problem)': False,\n",
       "  'contains(Flightr)': False,\n",
       "  'contains(says)': False,\n",
       "  'contains(planes)': False,\n",
       "  'contains(earlier)': False,\n",
       "  'contains(UA)': False,\n",
       "  'contains(credit)': False,\n",
       "  'contains(start)': False,\n",
       "  'contains(ok)': False,\n",
       "  'contains(voucher)': False,\n",
       "  'contains(working)': False,\n",
       "  'contains(Vegas)': False,\n",
       "  'contains(also)': False,\n",
       "  'contains(hotel)': False,\n",
       "  'contains(open)': False,\n",
       "  'contains(claim)': False,\n",
       "  'contains(pass)': False,\n",
       "  'contains(site)': False,\n",
       "  'contains(many)': False,\n",
       "  'contains(send)': False,\n",
       "  'contains(every)': False,\n",
       "  'contains(making)': False,\n",
       "  'contains(Now)': False,\n",
       "  'contains(departure)': False,\n",
       "  'contains(direct)': False,\n",
       "  'contains(attendant)': False,\n",
       "  'contains(come)': False,\n",
       "  'contains(line)': False,\n",
       "  'contains(gt)': False,\n",
       "  'contains(stuck)': False,\n",
       "  'contains(snow)': False,\n",
       "  'contains(app)': False,\n",
       "  'contains(https)': False,\n",
       "  'contains(reply)': False,\n",
       "  'contains(looking)': False,\n",
       "  'contains(person)': False,\n",
       "  'contains(Dallas)': False,\n",
       "  'contains(having)': False,\n",
       "  'contains(something)': False,\n",
       "  'contains(instead)': False,\n",
       "  'contains(update)': False,\n",
       "  'contains(missed)': False,\n",
       "  'contains(Houston)': False,\n",
       "  'contains(his)': False,\n",
       "  'contains(available)': False,\n",
       "  'contains(tried)': False,\n",
       "  'contains(When)': False,\n",
       "  'contains(add)': False,\n",
       "  'contains(away)': False,\n",
       "  'contains(Hi)': False,\n",
       "  'contains(question)': False,\n",
       "  'contains(air)': False,\n",
       "  'contains(Thx)': False,\n",
       "  'contains(card)': False,\n",
       "  'contains(called)': False,\n",
       "  'contains(rebooked)': False,\n",
       "  'contains(doing)': False,\n",
       "  'contains(ground)': False,\n",
       "  'contains(keep)': False,\n",
       "  'contains(nothing)': False,\n",
       "  'contains(pay)': False,\n",
       "  'contains(San)': False,\n",
       "  'contains(leave)': False,\n",
       "  'contains(until)': False,\n",
       "  'contains(flt)': False,\n",
       "  'contains(which)': False,\n",
       "  'contains(hear)': False,\n",
       "  'contains(missing)': False,\n",
       "  'contains(Southwest)': False,\n",
       "  'contains(received)': False,\n",
       "  'contains(soon)': False,\n",
       "  'contains(New)': False,\n",
       "  'contains(actually)': False,\n",
       "  'contains(contact)': False,\n",
       "  'contains(old)': False,\n",
       "  'contains(charge)': False,\n",
       "  'contains(thing)': False,\n",
       "  'contains(without)': False,\n",
       "  'contains(took)': False,\n",
       "  'contains(employees)': False,\n",
       "  'contains(connecting)': False,\n",
       "  'contains(understand)': False,\n",
       "  'contains(Imaginedragons)': False,\n",
       "  'contains(PHL)': False,\n",
       "  'contains(while)': False,\n",
       "  'contains(confirmation)': False,\n",
       "  'contains(tweet)': False,\n",
       "  'contains(taking)': False,\n",
       "  'contains(CEO)': False,\n",
       "  'contains(weeks)': False,\n",
       "  'contains(Yes)': False,\n",
       "  'contains(company)': False,\n",
       "  'contains(quick)': False,\n",
       "  'contains(Have)': False,\n",
       "  'contains(U)': False,\n",
       "  'contains(9)': False,\n",
       "  'contains(landed)': False,\n",
       "  'contains(few)': False,\n",
       "  'contains(isn)': False,\n",
       "  'contains(Love)': False,\n",
       "  'contains(IAH)': False,\n",
       "  'contains(full)': False,\n",
       "  'contains(policy)': False,\n",
       "  'contains(disappointed)': False,\n",
       "  'contains(least)': False,\n",
       "  'contains(different)': False,\n",
       "  'contains(kids)': False,\n",
       "  'contains(system)': False,\n",
       "  'contains(forward)': False,\n",
       "  'contains(She)': False,\n",
       "  'contains(far)': False,\n",
       "  'contains(possible)': False,\n",
       "  'contains(return)': False,\n",
       "  'contains(happy)': False,\n",
       "  'contains(family)': False,\n",
       "  'contains(link)': False,\n",
       "  'contains(pilot)': False,\n",
       "  'contains(landing)': False,\n",
       "  'contains(NYC)': False,\n",
       "  'contains(yesterday)': False,\n",
       "  'contains(cool)': False,\n",
       "  'contains(try)': False,\n",
       "  'contains(fee)': False,\n",
       "  'contains(BOS)': False,\n",
       "  'contains(rude)': False,\n",
       "  'contains(carry)': False,\n",
       "  'contains(both)': False,\n",
       "  'contains(On)': False,\n",
       "  'contains(broken)': False,\n",
       "  'contains(coming)': False,\n",
       "  'contains(changed)': False,\n",
       "  'contains(plus)': False,\n",
       "  'contains(mins)': False,\n",
       "  'contains(used)': False,\n",
       "  'contains(American)': False,\n",
       "  'contains(YOU)': False,\n",
       "  'contains(destination)': False,\n",
       "  'contains(him)': False,\n",
       "  'contains(paid)': False,\n",
       "  'contains(wasn)': False,\n",
       "  'contains(Boston)': False,\n",
       "  'contains(found)': False,\n",
       "  'contains(Airlines)': False,\n",
       "  'contains(extra)': False,\n",
       "  'contains(Airways)': False,\n",
       "  'contains(Delta)': False,\n",
       "  'contains(fix)': False,\n",
       "  'contains(haven)': False,\n",
       "  'contains(UnitedAirlines)': False,\n",
       "  'contains(needs)': False,\n",
       "  'contains(Are)': False,\n",
       "  'contains(wife)': False,\n",
       "  'contains(Help)': False,\n",
       "  'contains(sorry)': False,\n",
       "  'contains(Still)': False,\n",
       "  'contains(offer)': False,\n",
       "  'contains(using)': False,\n",
       "  'contains(little)': False,\n",
       "  'contains(stop)': False,\n",
       "  'contains(once)': False,\n",
       "  'contains(mean)': False,\n",
       "  'contains(Was)': False,\n",
       "  'contains(pilots)': False,\n",
       "  'contains(car)': False,\n",
       "  'contains(went)': False,\n",
       "  'contains(hard)': False,\n",
       "  'contains(might)': False,\n",
       "  'contains(message)': False,\n",
       "  'contains(during)': False,\n",
       "  'contains(Good)': False,\n",
       "  'contains(terrible)': False,\n",
       "  'contains(Twitter)': False,\n",
       "  'contains(50)': False,\n",
       "  'contains(Don)': False,\n",
       "  'contains(option)': False,\n",
       "  'contains(together)': False,\n",
       "  'contains(vacation)': False,\n",
       "  'contains(FLL)': False,\n",
       "  'contains(traveling)': False,\n",
       "  'contains(rep)': False,\n",
       "  'contains(lt)': False,\n",
       "  'contains(reason)': False,\n",
       "  'contains(less)': False,\n",
       "  'contains(24)': False,\n",
       "  'contains(food)': False,\n",
       "  'contains(most)': False,\n",
       "  'contains(11)': False,\n",
       "  'contains(big)': False,\n",
       "  'contains(around)': False,\n",
       "  'contains(jetblue)': False,\n",
       "  'contains(second)': False,\n",
       "  'contains(Need)': False,\n",
       "  'contains(mechanical)': False,\n",
       "  'contains(THE)': False,\n",
       "  'contains(may)': False,\n",
       "  'contains(lot)': False,\n",
       "  'contains(anyone)': False,\n",
       "  'contains(point)': False,\n",
       "  'contains(everyone)': False,\n",
       "  'contains(rebook)': False,\n",
       "  'contains(25)': False,\n",
       "  'contains(points)': False,\n",
       "  'contains(things)': False,\n",
       "  'contains(45)': False,\n",
       "  'contains(DEN)': False,\n",
       "  'contains(these)': False,\n",
       "  'contains(friend)': False,\n",
       "  'contains(enough)': False,\n",
       "  'contains(2015)': False,\n",
       "  'contains(gave)': False,\n",
       "  'contains(looks)': False,\n",
       "  'contains(account)': False,\n",
       "  'contains(CLT)': False,\n",
       "  'contains(own)': False,\n",
       "  'contains(ur)': False,\n",
       "  'contains(room)': False,\n",
       "  'contains(international)': False,\n",
       "  'contains(couldn)': False,\n",
       "  'contains(everything)': False,\n",
       "  'contains(LA)': True,\n",
       "  'contains(assistance)': False,\n",
       "  'contains(hi)': False,\n",
       "  'contains(world)': False,\n",
       "  'contains(form)': False,\n",
       "  'contains(leaving)': False,\n",
       "  'contains(row)': False,\n",
       "  'contains(money)': False,\n",
       "  'contains(wanted)': False,\n",
       "  'contains(makes)': False,\n",
       "  'contains(y)': False,\n",
       "  'contains(hoping)': False,\n",
       "  'contains(oh)': False,\n",
       "  'contains(past)': False,\n",
       "  'contains(group)': False,\n",
       "  'contains(desk)': False,\n",
       "  'contains(Really)': False,\n",
       "  'contains(idea)': False,\n",
       "  'contains(ask)': False,\n",
       "  'contains(each)': False,\n",
       "  'contains(DCA)': False,\n",
       "  'contains(maintenance)': False,\n",
       "  'contains(asked)': False,\n",
       "  'contains(happened)': False,\n",
       "  'contains(speak)': False,\n",
       "  'contains(200)': False,\n",
       "  'contains(bring)': False,\n",
       "  'contains(40)': False,\n",
       "  'contains(appreciated)': False,\n",
       "  'contains(following)': False,\n",
       "  'contains(Nashville)': False,\n",
       "  'contains(case)': False,\n",
       "  'contains(such)': False,\n",
       "  'contains(problems)': False,\n",
       "  'contains(Airport)': False,\n",
       "  'contains(thx)': False,\n",
       "  'contains(terminal)': False,\n",
       "  'contains(Gate)': False,\n",
       "  'contains(Looking)': False,\n",
       "  'contains(100)': False,\n",
       "  'contains(under)': False,\n",
       "  'contains(given)': False,\n",
       "  'contains(changes)': False,\n",
       "  'contains(details)': False,\n",
       "  'contains(fees)': False,\n",
       "  'contains(sit)': False,\n",
       "  'contains(Atlanta)': False,\n",
       "  'contains(supposed)': False,\n",
       "  'contains(Very)': False,\n",
       "  'contains(checking)': False,\n",
       "  'contains(In)': False,\n",
       "  'contains(DC)': False,\n",
       "  'contains(month)': False,\n",
       "  'contains(Austin)': False,\n",
       "  'contains(All)': False,\n",
       "  'contains(leg)': False,\n",
       "  'contains(wrong)': False,\n",
       "  'contains(stay)': False,\n",
       "  'contains(correct)': False,\n",
       "  'contains(cold)': False,\n",
       "  'contains(almost)': False,\n",
       "  'contains(non)': False,\n",
       "  'contains(believe)': False,\n",
       "  'contains(frustrated)': False,\n",
       "  'contains(arrived)': False,\n",
       "  'contains(currently)': False,\n",
       "  'contains(SWA)': False,\n",
       "  'contains(process)': False,\n",
       "  'contains(poor)': False,\n",
       "  'contains(arrive)': False,\n",
       "  'contains(lol)': False,\n",
       "  'contains(longer)': False,\n",
       "  'contains(attendants)': False,\n",
       "  'contains(taken)': False,\n",
       "  'contains(half)': False,\n",
       "  'contains(Customer)': False,\n",
       "  'contains(date)': False,\n",
       "  'contains(end)': False,\n",
       "  'contains(companion)': False,\n",
       "  'contains(cost)': False,\n",
       "  'contains(Wall)': False,\n",
       "  'contains(life)': False,\n",
       "  'contains(southwestair)': False,\n",
       "  'contains(heard)': False,\n",
       "  'contains(scheduled)': False,\n",
       "  'contains(Sunday)': False,\n",
       "  'contains(request)': False,\n",
       "  'contains(share)': False,\n",
       "  'contains(thru)': False,\n",
       "  'contains(years)': False,\n",
       "  'contains(bc)': False,\n",
       "  'contains(between)': False,\n",
       "  'contains(MCO)': False,\n",
       "  'contains(deal)': False,\n",
       "  'contains(address)': False,\n",
       "  'contains(He)': False,\n",
       "  'contains(guy)': False,\n",
       "  'contains(fail)': False,\n",
       "  'contains(set)': False,\n",
       "  'contains(minute)': False,\n",
       "  'contains(award)': False,\n",
       "  'contains(sleep)': False,\n",
       "  'contains(asking)': False,\n",
       "  'contains(schedule)': False,\n",
       "  'contains(reFlight)': False,\n",
       "  'contains(ready)': False,\n",
       "  'contains(price)': False,\n",
       "  'contains(wonderful)': False,\n",
       "  'contains(Let)': False,\n",
       "  'contains(LGA)': False,\n",
       "  'contains(super)': False,\n",
       "  'contains(worries)': False,\n",
       "  'contains(Monday)': False,\n",
       "  'contains(Only)': False,\n",
       "  'contains(tarmac)': False,\n",
       "  'contains(2nd)': False,\n",
       "  'contains(standby)': False,\n",
       "  'contains(worse)': False,\n",
       "  'contains(purchase)': False,\n",
       "  'contains(pretty)': False,\n",
       "  'contains(easy)': False,\n",
       "  'contains(Got)': False,\n",
       "  'contains(feel)': False,\n",
       "  'contains(stranded)': False,\n",
       "  'contains(real)': False,\n",
       "  'contains(complaint)': False,\n",
       "  'contains(Never)': False,\n",
       "  'contains(12)': False,\n",
       "  'contains(cabin)': False,\n",
       "  'contains(Well)': False,\n",
       "  'contains(Maybe)': False,\n",
       "  'contains(confirmed)': False,\n",
       "  'contains(friends)': False,\n",
       "  'contains(course)': False,\n",
       "  'contains(BWI)': False,\n",
       "  'contains(Would)': False,\n",
       "  'contains(Another)': False,\n",
       "  'contains(SW)': False,\n",
       "  'contains(member)': False,\n",
       "  'contains(LAS)': False,\n",
       "  'contains(empty)': False,\n",
       "  'contains(moved)': False,\n",
       "  'contains(boarded)': False,\n",
       "  'contains(space)': False,\n",
       "  'contains(months)': False,\n",
       "  'contains(horrible)': False,\n",
       "  'contains(happen)': False,\n",
       "  'contains(Awesome)': False,\n",
       "  'contains(yr)': False,\n",
       "  'contains(loyal)': False,\n",
       "  'contains(Virgin)': False,\n",
       "  'contains(giving)': False,\n",
       "  'contains(else)': False,\n",
       "  'contains(glad)': False,\n",
       "  'contains(seem)': False,\n",
       "  'contains(weekend)': False,\n",
       "  'contains(excellent)': False,\n",
       "  'contains(round)': False,\n",
       "  'contains(read)': False,\n",
       "  'contains(flown)': False,\n",
       "  'contains(guess)': False,\n",
       "  'contains(There)': False,\n",
       "  'contains(seating)': False,\n",
       "  'contains(seriously)': False,\n",
       "  'contains(helping)': False,\n",
       "  'contains(fine)': False,\n",
       "  'contains(saying)': False,\n",
       "  'contains(clothes)': False,\n",
       "  'contains(hung)': False,\n",
       "  'contains(Also)': False,\n",
       "  'contains(twice)': False,\n",
       "  'contains(C)': False,\n",
       "  'contains(happens)': False,\n",
       "  'contains(needed)': False,\n",
       "  'contains(child)': False,\n",
       "  'contains(talk)': False,\n",
       "  'contains(dm)': False,\n",
       "  'contains(route)': False,\n",
       "  'contains(fare)': False,\n",
       "  'contains(future)': False,\n",
       "  'contains(Had)': False,\n",
       "  'contains(Did)': False,\n",
       "  'contains(reservations)': False,\n",
       "  'contains(apology)': False,\n",
       "  'contains(wouldn)': False,\n",
       "  'contains(entire)': False,\n",
       "  'contains(bought)': False,\n",
       "  'contains(provide)': False,\n",
       "  'contains(mileage)': False,\n",
       "  'contains(support)': False,\n",
       "  'contains(At)': False,\n",
       "  'contains(Feb)': False,\n",
       "  'contains(Orlando)': False,\n",
       "  'contains(information)': False,\n",
       "  'contains(options)': False,\n",
       "  'contains(afternoon)': False,\n",
       "  'contains(ATL)': False,\n",
       "  'contains(calling)': False,\n",
       "  'contains(wish)': False,\n",
       "  'contains(Air)': False,\n",
       "  'contains(luck)': False,\n",
       "  'contains(access)': False,\n",
       "  'contains(flew)': False,\n",
       "  'contains(either)': False,\n",
       "  'contains(passenger)': False,\n",
       "  'contains(confirm)': False,\n",
       "  'contains(overhead)': False,\n",
       "  'contains(members)': False,\n",
       "  'contains(birthday)': False,\n",
       "  'contains(excited)': False,\n",
       "  'contains(came)': False,\n",
       "  'contains(March)': False,\n",
       "  'contains(Flightlations)': False,\n",
       "  'contains(ride)': False,\n",
       "  'contains(connections)': False,\n",
       "  'contains(respond)': False,\n",
       "  'contains(maybe)': False,\n",
       "  'contains(three)': False,\n",
       "  'contains(favorite)': False,\n",
       "  'contains(mine)': False,\n",
       "  'contains(win)': False,\n",
       "  'contains(saw)': False,\n",
       "  'contains(First)': False,\n",
       "  'contains(ridiculous)': False,\n",
       "  'contains(lounge)': False,\n",
       "  'contains(top)': False,\n",
       "  'contains(safety)': False,\n",
       "  'contains(NOT)': False,\n",
       "  'contains(thought)': False,\n",
       "  'contains(sucks)': False,\n",
       "  'contains(daughter)': False,\n",
       "  'contains(pick)': False,\n",
       "  'contains(aircraft)': False,\n",
       "  'contains(supervisor)': False,\n",
       "  'contains(checkin)': False,\n",
       "  'contains(virginamerica)': False,\n",
       "  'contains(services)': False,\n",
       "  'contains(helped)': False,\n",
       "  'contains(place)': False,\n",
       "  'contains(See)': False,\n",
       "  'contains(sense)': False,\n",
       "  'contains(joke)': False,\n",
       "  'contains(record)': False,\n",
       "  'contains(1K)': False,\n",
       "  'contains(cust)': False,\n",
       "  'contains(lose)': False,\n",
       "  'contains(answer)': False,\n",
       "  'contains(kind)': False,\n",
       "  'contains(buy)': False,\n",
       "  'contains(allowed)': False,\n",
       "  'contains(beyond)': False,\n",
       "  'contains(running)': False,\n",
       "  'contains(avgeek)': False,\n",
       "  'contains(code)': False,\n",
       "  'contains(Flying)': False,\n",
       "  'contains(error)': False,\n",
       "  'contains(true)': False,\n",
       "  'contains(Hey)': False,\n",
       "  'contains(After)': False,\n",
       "  'contains(middle)': False,\n",
       "  'contains(fixed)': False,\n",
       "  'contains(domestic)': False,\n",
       "  'contains(updates)': False,\n",
       "  'contains(situation)': False,\n",
       "  'contains(switch)': False,\n",
       "  'contains(Club)': False,\n",
       "  'contains(rock)': False,\n",
       "  'contains(okay)': False,\n",
       "  'contains(video)': False,\n",
       "  'contains(overnight)': False,\n",
       "  'contains(offering)': False,\n",
       "  'contains(seems)': False,\n",
       "  'contains(expect)': False,\n",
       "  'contains(aren)': False,\n",
       "  'contains(warm)': False,\n",
       "  'contains(hr)': False,\n",
       "  'contains(son)': False,\n",
       "  'contains(TO)': False,\n",
       "  'contains(telling)': False,\n",
       "  'contains(layover)': False,\n",
       "  'contains(transfer)': False,\n",
       "  'contains(b)': False,\n",
       "  'contains(TSA)': False,\n",
       "  'contains(Nice)': False,\n",
       "  'contains(One)': False,\n",
       "  'contains(Pls)': False,\n",
       "  'contains(23)': False,\n",
       "  'contains(May)': False,\n",
       "  'contains(iPhone)': False,\n",
       "  'contains(jet)': False,\n",
       "  'contains(Could)': False,\n",
       "  'contains(list)': False,\n",
       "  'contains(customerservice)': False,\n",
       "  'contains(rather)': False,\n",
       "  'contains(PLEASE)': False,\n",
       "  'contains(Friday)': False,\n",
       "  'contains(Street)': False,\n",
       "  'contains(cause)': False,\n",
       "  'contains(goes)': False,\n",
       "  'contains(Should)': False,\n",
       "  'contains(ME)': False,\n",
       "  'contains(17)': False,\n",
       "  'contains(fun)': False,\n",
       "  'contains(Or)': False,\n",
       "  'contains(myself)': False,\n",
       "  'contains(Keep)': False,\n",
       "  'contains(learn)': False,\n",
       "  'contains(works)': False,\n",
       "  'contains(pre)': False,\n",
       "  'contains(arrival)': False,\n",
       "  'contains(compensation)': False,\n",
       "  'contains(part)': False,\n",
       "  'contains(hey)': False,\n",
       "  'contains(southwest)': False,\n",
       "  'contains(Flighting)': False,\n",
       "  'contains(PHX)': False,\n",
       "  'contains(THANK)': False,\n",
       "  'contains(employee)': False,\n",
       "  'contains(live)': False,\n",
       "  'contains(RDU)': False,\n",
       "  'contains(Charlotte)': False,\n",
       "  'contains(entertainment)': False,\n",
       "  'contains(crossed)': False,\n",
       "  'contains(figure)': False,\n",
       "  'contains(welcome)': False,\n",
       "  'contains(c)': False,\n",
       "  'contains(original)': False,\n",
       "  'contains(DAL)': False,\n",
       "  'contains(match)': False,\n",
       "  'contains(resolved)': False,\n",
       "  'contains(AM)': False,\n",
       "  'contains(awful)': False,\n",
       "  'contains(gets)': False,\n",
       "  'contains(changing)': False,\n",
       "  'contains(tix)': False,\n",
       "  'contains(takes)': False,\n",
       "  'contains(area)': False,\n",
       "  'contains(responding)': False,\n",
       "  'contains(small)': False,\n",
       "  'contains(storm)': False,\n",
       "  'contains(must)': False,\n",
       "  'contains(fault)': False,\n",
       "  'contains(feedback)': False,\n",
       "  'contains(high)': False,\n",
       "  'contains(Trying)': False,\n",
       "  'contains(Worst)': False,\n",
       "  'contains(winter)': False,\n",
       "  'contains(delivered)': False,\n",
       "  'contains(despite)': False,\n",
       "  'contains(evening)': False,\n",
       "  'contains(means)': False,\n",
       "  'contains(800)': False,\n",
       "  'contains(PDX)': False,\n",
       "  'contains(several)': False,\n",
       "  'contains(ice)': False,\n",
       "  'contains(frustrating)': False,\n",
       "  'contains(haha)': False,\n",
       "  'contains(safe)': False,\n",
       "  'contains(husband)': False,\n",
       "  'contains(D)': False,\n",
       "  'contains(fares)': False,\n",
       "  'contains(offered)': False,\n",
       "  'contains(Saturday)': False,\n",
       "  'contains(counter)': False,\n",
       "  'contains(mind)': False,\n",
       "  'contains(r)': False,\n",
       "  'contains(suck)': False,\n",
       "  'contains(party)': False,\n",
       "  'contains(showing)': False,\n",
       "  'contains(Mexico)': False,\n",
       "  'contains(Service)': False,\n",
       "  'contains(Who)': False,\n",
       "  'contains(pls)': False,\n",
       "  'contains(Kudos)': False,\n",
       "  'contains(ASAP)': False,\n",
       "  'contains(advisory)': False,\n",
       "  'contains(deals)': False,\n",
       "  'contains(probably)': False,\n",
       "  'contains(35)': False,\n",
       "  'contains(computer)': False,\n",
       "  'contains(As)': False,\n",
       "  'contains(Appreciate)': False,\n",
       "  'contains(MY)': False,\n",
       "  'contains(upgrades)': False,\n",
       "  'contains(hate)': False,\n",
       "  'contains(America)': False,\n",
       "  'contains(held)': False,\n",
       "  'contains(ARE)': False,\n",
       "  'contains(Hopefully)': False,\n",
       "  'contains(order)': False,\n",
       "  'contains(Flightlation)': False,\n",
       "  'contains(TV)': False,\n",
       "  'contains(definitely)': False,\n",
       "  'contains(followed)': False,\n",
       "  'contains(worth)': False,\n",
       "  'contains(others)': False,\n",
       "  'contains(load)': False,\n",
       "  'contains(Hello)': False,\n",
       "  'contains(drive)': False,\n",
       "  'contains(whole)': False,\n",
       "  'contains(priority)': False,\n",
       "  'contains(For)': False,\n",
       "  'contains(land)': False,\n",
       "  'contains(plans)': False,\n",
       "  'contains(run)': False,\n",
       "  'contains(o)': False,\n",
       "  'contains(note)': False,\n",
       "  'contains(flyer)': False,\n",
       "  'contains(added)': False,\n",
       "  'contains(frequent)': False,\n",
       "  'contains(above)': False,\n",
       "  'contains(S)': False,\n",
       "  'contains(allow)': False,\n",
       "  'contains(onboard)': False,\n",
       "  'contains(baby)': False,\n",
       "  'contains(seen)': False,\n",
       "  'contains(Does)': False,\n",
       "  'contains(waited)': False,\n",
       "  'contains(paying)': False,\n",
       "  'contains(Been)': False,\n",
       "  'contains(report)': False,\n",
       "  'contains(charged)': False,\n",
       "  'contains(view)': False,\n",
       "  'contains(front)': False,\n",
       "  'contains(folks)': False,\n",
       "  'contains(Journal)': False,\n",
       "  'contains(totally)': False,\n",
       "  'contains(keeping)': False,\n",
       "  'contains(Oh)': False,\n",
       "  ...},\n",
       " 'positive')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now we apply the function to the document dataset\n",
    "featuresets = [(document_features(d, word_features), c) for (d, c) in docs]\n",
    "   \n",
    "#we print the list of features matches for the first document ([0]) in the corpus\n",
    "#we'll see a Python dictionary with the key being the feature word\n",
    "#and the value being 'True' or 'False' according to that word being matched in the present document or not\n",
    "#we'll se a lot of 'False' values because (of course) not all 2000 words will be on each sentence!\n",
    "featuresets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d8169bfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8456"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking the length of the list of features\n",
    "len(featuresets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e3a97d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We are ready now to do machine learning using the unigram list we just created\n",
    "#we use a Naive Bayes classifier with 5-fold cross validation for training on sentiments using unigrams\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c97c918f",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits = 5)\n",
    "sum = 0\n",
    "\n",
    "for train, test in kf.split(featuresets):\n",
    "    train_data = np.array(featuresets)[train]\n",
    "    test_data = np.array(featuresets)[test]\n",
    "    classifier = nltk.NaiveBayesClassifier.train(train_data)\n",
    "    sum += nltk.classify.accuracy(classifier, test_data)\n",
    "\n",
    "#storing the score in a variable \n",
    "acc1 = sum/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "49b65bd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7712851936199572"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's see the accuracy score for this unigram classifier\n",
    "\n",
    "acc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0a6eb7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will now create a new feature: bigrams\n",
    "#we'll use the code we already know from class labs \n",
    "\n",
    "from nltk.collocations import *\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "84b029f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data cleaning and preprocessing\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "def alpha(w):\n",
    "    pattern = re.compile('^[^a-z]+$')\n",
    "    if(pattern.match(w)):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6dc06819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('customer', 'service'), 0.0016738218465266446),\n",
       " (('Cancelled', 'Flightled'), 0.0010715261193245884),\n",
       " (('JetBlue', 'Our'), 0.0008194023265423322),\n",
       " (('Late', 'Flight'), 0.0008194023265423322),\n",
       " (('Our', 'fleet'), 0.0008123988878539363),\n",
       " (('fleek', 'http'), 0.0008053954491655402),\n",
       " (('united', 'thanks'), 0.0005742819724484722),\n",
       " (('Booking', 'Problems'), 0.0005672785337600762),\n",
       " (('Cancelled', 'Flighted'), 0.00046222695343413616),\n",
       " (('Thanks', 'united'), 0.0004342131986805521)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating bigrams features for the corpus and applying cleaning steps\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "finder = BigramCollocationFinder.from_words(all_words)\n",
    "finder.apply_word_filter(alpha)\n",
    "finder.apply_word_filter(lambda w: w in stopwords)\n",
    "scored = finder.score_ngrams(bigram_measures.raw_freq)\n",
    "scored[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fa66fb4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('customer', 'service'),\n",
       " ('Cancelled', 'Flightled'),\n",
       " ('JetBlue', 'Our'),\n",
       " ('Late', 'Flight'),\n",
       " ('Our', 'fleet'),\n",
       " ('fleek', 'http'),\n",
       " ('united', 'thanks'),\n",
       " ('Booking', 'Problems'),\n",
       " ('Cancelled', 'Flighted'),\n",
       " ('Thanks', 'united'),\n",
       " ('Flight', 'Booking'),\n",
       " ('JetBlue', 'thanks'),\n",
       " ('Late', 'Flightr'),\n",
       " ('Cancelled', 'Flight'),\n",
       " ('united', 'yes'),\n",
       " ('united', 'thank'),\n",
       " ('AmericanAir', 'thanks'),\n",
       " ('united', 'flight'),\n",
       " ('flight', 'united'),\n",
       " ('united', 'Thanks'),\n",
       " ('thanks', 'united'),\n",
       " ('SouthwestAir', 'thanks'),\n",
       " ('first', 'class'),\n",
       " ('SouthwestAir', 'Thanks'),\n",
       " ('USAirways', 'thanks'),\n",
       " ('connecting', 'flight'),\n",
       " ('service', 'united'),\n",
       " ('flight', 'attendant'),\n",
       " ('help', 'united'),\n",
       " ('JetBlue', 'thank')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extracting clean bigrams (no frequency information)\n",
    "bigram_features = [bigram for (bigram, count) in scored[:2000]]\n",
    "\n",
    "#printing the first 30 for confirmation\n",
    "bigram_features[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a928abb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#after finding all bigrams of the corpus (i.e. the bigram feature of the corpus)\n",
    "#we create a function that checks if those feature bigrams are present on each specific document\n",
    "#exactly as we did with unigrams\\n\",\n",
    "\n",
    "def bi_document_features(document, bigram_features):\n",
    "    document_words = list(nltk.bigrams(document))\n",
    "    features = {}\n",
    "    for word in bigram_features:\n",
    "        #boolean logic will retunt 'True' if there is a match, or 'False' if not\n",
    "        features['contains({})'.format(word)] = (word in document_words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cc5afe34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({\"contains(('customer', 'service'))\": False,\n",
       "  \"contains(('Cancelled', 'Flightled'))\": False,\n",
       "  \"contains(('JetBlue', 'Our'))\": False,\n",
       "  \"contains(('Late', 'Flight'))\": False,\n",
       "  \"contains(('Our', 'fleet'))\": False,\n",
       "  \"contains(('fleek', 'http'))\": False,\n",
       "  \"contains(('united', 'thanks'))\": False,\n",
       "  \"contains(('Booking', 'Problems'))\": False,\n",
       "  \"contains(('Cancelled', 'Flighted'))\": False,\n",
       "  \"contains(('Thanks', 'united'))\": False,\n",
       "  \"contains(('Flight', 'Booking'))\": False,\n",
       "  \"contains(('JetBlue', 'thanks'))\": False,\n",
       "  \"contains(('Late', 'Flightr'))\": False,\n",
       "  \"contains(('Cancelled', 'Flight'))\": False,\n",
       "  \"contains(('united', 'yes'))\": False,\n",
       "  \"contains(('united', 'thank'))\": False,\n",
       "  \"contains(('AmericanAir', 'thanks'))\": False,\n",
       "  \"contains(('united', 'flight'))\": False,\n",
       "  \"contains(('flight', 'united'))\": False,\n",
       "  \"contains(('united', 'Thanks'))\": False,\n",
       "  \"contains(('thanks', 'united'))\": False,\n",
       "  \"contains(('SouthwestAir', 'thanks'))\": False,\n",
       "  \"contains(('first', 'class'))\": False,\n",
       "  \"contains(('SouthwestAir', 'Thanks'))\": False,\n",
       "  \"contains(('USAirways', 'thanks'))\": False,\n",
       "  \"contains(('connecting', 'flight'))\": False,\n",
       "  \"contains(('service', 'united'))\": False,\n",
       "  \"contains(('flight', 'attendant'))\": False,\n",
       "  \"contains(('help', 'united'))\": False,\n",
       "  \"contains(('JetBlue', 'thank'))\": False,\n",
       "  \"contains(('gate', 'agent'))\": False,\n",
       "  \"contains(('united', 'Thank'))\": False,\n",
       "  \"contains(('Thanks', 'SouthwestAir'))\": False,\n",
       "  \"contains(('You', 'guys'))\": False,\n",
       "  \"contains(('get', 'home'))\": False,\n",
       "  \"contains(('1st', 'class'))\": False,\n",
       "  \"contains(('SouthwestAir', 'thank'))\": False,\n",
       "  \"contains(('last', 'night'))\": False,\n",
       "  \"contains(('would', 'like'))\": False,\n",
       "  \"contains(('AmericanAir', 'Thank'))\": False,\n",
       "  \"contains(('SouthwestAir', 'Thank'))\": False,\n",
       "  \"contains(('boarding', 'pass'))\": False,\n",
       "  \"contains(('great', 'flight'))\": False,\n",
       "  \"contains(('next', 'flight'))\": False,\n",
       "  \"contains(('reFlight', 'Booking'))\": False,\n",
       "  \"contains(('JetBlue', 'Thanks'))\": False,\n",
       "  \"contains(('first', 'time'))\": False,\n",
       "  \"contains(('united', 'You'))\": False,\n",
       "  \"contains(('united', 'please'))\": False,\n",
       "  \"contains(('would', 'love'))\": False,\n",
       "  \"contains(('Thanks', 'JetBlue'))\": False,\n",
       "  \"contains(('USAirways', 'AmericanAir'))\": False,\n",
       "  \"contains(('looks', 'like'))\": False,\n",
       "  \"contains(('AmericanAir', 'thank'))\": False,\n",
       "  \"contains(('checked', 'bag'))\": False,\n",
       "  \"contains(('help', 'SouthwestAir'))\": False,\n",
       "  \"contains(('hour', 'delay'))\": False,\n",
       "  \"contains(('time', 'united'))\": False,\n",
       "  \"contains(('AmericanAir', 'Thanks'))\": False,\n",
       "  \"contains(('USAirways', 'thank'))\": False,\n",
       "  \"contains(('earlier', 'flight'))\": False,\n",
       "  \"contains(('tomorrow', 'united'))\": False,\n",
       "  \"contains(('Cancelled', 'Flightlations'))\": False,\n",
       "  \"contains(('JetBlue', 'Airways'))\": False,\n",
       "  \"contains(('please', 'help'))\": False,\n",
       "  \"contains(('tomorrow', 'morning'))\": False,\n",
       "  \"contains(('flight', 'tomorrow'))\": False,\n",
       "  \"contains(('much', 'united'))\": False,\n",
       "  \"contains(('quick', 'response'))\": False,\n",
       "  \"contains(('today', 'united'))\": False,\n",
       "  \"contains(('united', 'Flight'))\": False,\n",
       "  \"contains(('united', 'It'))\": False,\n",
       "  \"contains(('wait', 'time'))\": False,\n",
       "  \"contains(('Cancelled', 'Flighting'))\": False,\n",
       "  \"contains(('JetBlue', 'Thank'))\": False,\n",
       "  \"contains(('Wall', 'Street'))\": False,\n",
       "  \"contains(('bag', 'united'))\": False,\n",
       "  \"contains(('baggage', 'claim'))\": False,\n",
       "  \"contains(('flight', 'attendants'))\": False,\n",
       "  \"contains(('hours', 'Late'))\": False,\n",
       "  \"contains(('united', 'Why'))\": False,\n",
       "  \"contains(('airline', 'united'))\": False,\n",
       "  \"contains(('email', 'address'))\": False,\n",
       "  \"contains(('even', 'though'))\": False,\n",
       "  \"contains(('home', 'united'))\": False,\n",
       "  \"contains(('let', 'us'))\": False,\n",
       "  \"contains(('united', 'Hi'))\": False,\n",
       "  \"contains(('united', 'Yes'))\": False,\n",
       "  \"contains(('Cancelled', 'Flightlation'))\": False,\n",
       "  \"contains(('Looking', 'forward'))\": False,\n",
       "  \"contains(('confirmation', 'number'))\": False,\n",
       "  \"contains(('flight', 'Cancelled'))\": False,\n",
       "  \"contains(('great', 'job'))\": False,\n",
       "  \"contains(('last', 'week'))\": False,\n",
       "  \"contains(('round', 'trip'))\": False,\n",
       "  \"contains(('united', 'How'))\": False,\n",
       "  \"contains(('USAirways', 'Thank'))\": False,\n",
       "  \"contains(('another', 'flight'))\": False,\n",
       "  \"contains(('day', 'united'))\": False,\n",
       "  \"contains(('delayed', 'due'))\": False,\n",
       "  \"contains(('delayed', 'flight'))\": False,\n",
       "  \"contains(('flight', 'JetBlue'))\": False,\n",
       "  \"contains(('flight', 'SouthwestAir'))\": False,\n",
       "  \"contains(('flights', 'united'))\": False,\n",
       "  \"contains(('good', 'work'))\": False,\n",
       "  \"contains(('phone', 'number'))\": False,\n",
       "  \"contains(('please', 'united'))\": False,\n",
       "  \"contains(('united', 'No'))\": False,\n",
       "  \"contains(('united', 'What'))\": False,\n",
       "  \"contains(('united', 'well'))\": False,\n",
       "  \"contains(('JetBlue', 'flight'))\": False,\n",
       "  \"contains(('San', 'Diego'))\": False,\n",
       "  \"contains(('Thanks', 'AmericanAir'))\": False,\n",
       "  \"contains(('United', 'Airlines'))\": False,\n",
       "  \"contains(('United', 'flight'))\": False,\n",
       "  \"contains(('appease', 'passengers'))\": False,\n",
       "  \"contains(('companion', 'pass'))\": False,\n",
       "  \"contains(('credit', 'card'))\": False,\n",
       "  \"contains(('done', 'united'))\": False,\n",
       "  \"contains(('flight', 'crew'))\": False,\n",
       "  \"contains(('need', 'help'))\": False,\n",
       "  \"contains(('response', 'united'))\": False,\n",
       "  \"contains(('united', 'My'))\": False,\n",
       "  \"contains(('united', 'The'))\": False,\n",
       "  \"contains(('united', 'airlines'))\": False,\n",
       "  \"contains(('another', 'airline'))\": False,\n",
       "  \"contains(('could', 'get'))\": False,\n",
       "  \"contains(('customer', 'care'))\": False,\n",
       "  \"contains(('still', 'waiting'))\": False,\n",
       "  \"contains(('thanks', 'JetBlue'))\": False,\n",
       "  \"contains(('thanks', 'SouthwestAir'))\": False,\n",
       "  \"contains(('united', 'Just'))\": False,\n",
       "  \"contains(('united', 'Your'))\": False,\n",
       "  \"contains(('united', 'still'))\": False,\n",
       "  \"contains(('worst', 'airline'))\": False,\n",
       "  \"contains(('AmericanAir', 'yes'))\": False,\n",
       "  \"contains(('Fingers', 'crossed'))\": False,\n",
       "  \"contains(('How', 'long'))\": False,\n",
       "  \"contains(('Please', 'help'))\": False,\n",
       "  \"contains(('SouthwestAir', 'FortuneMagazine'))\": False,\n",
       "  \"contains(('direct', 'flight'))\": False,\n",
       "  \"contains(('direct', 'flights'))\": False,\n",
       "  \"contains(('every', 'time'))\": False,\n",
       "  \"contains(('flight', 'home'))\": False,\n",
       "  \"contains(('great', 'customer'))\": False,\n",
       "  \"contains(('lt', 'lt'))\": False,\n",
       "  \"contains(('make', 'sure'))\": False,\n",
       "  \"contains(('mechanical', 'issues'))\": False,\n",
       "  \"contains(('next', 'time'))\": False,\n",
       "  \"contains(('one', 'way'))\": False,\n",
       "  \"contains(('thanks', 'AmericanAir'))\": False,\n",
       "  \"contains(('time', 'flying'))\": False,\n",
       "  \"contains(('today', 'SouthwestAir'))\": False,\n",
       "  \"contains(('united', 'Can'))\": False,\n",
       "  \"contains(('Any', 'chance'))\": False,\n",
       "  \"contains(('Any', 'way'))\": False,\n",
       "  \"contains(('At', 'least'))\": False,\n",
       "  \"contains(('Journal', 'http'))\": False,\n",
       "  \"contains(('Just', 'sent'))\": False,\n",
       "  \"contains(('SouthwestAir', 'Can'))\": False,\n",
       "  \"contains(('SouthwestAir', 'Just'))\": False,\n",
       "  \"contains(('Thanks', 'USAirways'))\": False,\n",
       "  \"contains(('Thanks', 'VirginAmerica'))\": False,\n",
       "  \"contains(('b', 'c'))\": False,\n",
       "  \"contains(('best', 'airline'))\": False,\n",
       "  \"contains(('change', 'fee'))\": False,\n",
       "  \"contains(('gate', 'agents'))\": False,\n",
       "  \"contains(('get', 'us'))\": False,\n",
       "  \"contains(('last', 'flight'))\": False,\n",
       "  \"contains(('looking', 'forward'))\": False,\n",
       "  \"contains(('return', 'flight'))\": False,\n",
       "  \"contains(('thanks', 'USAirways'))\": False,\n",
       "  \"contains(('united', 'That'))\": False,\n",
       "  \"contains(('united', 'We'))\": False,\n",
       "  \"contains(('united', 'ok'))\": False,\n",
       "  \"contains(('united', 'worst'))\": False,\n",
       "  \"contains(('Flight', 'flight'))\": False,\n",
       "  \"contains(('Flightled', 'flight'))\": False,\n",
       "  \"contains(('SouthwestAir', 'love_dragonss'))\": False,\n",
       "  \"contains(('SouthwestAir', 'yes'))\": False,\n",
       "  \"contains(('United', 'united'))\": False,\n",
       "  \"contains(('UnitedAirlines', 'united'))\": False,\n",
       "  \"contains(('VirginAmerica', 'thanks'))\": False,\n",
       "  \"contains(('bad', 'weather'))\": False,\n",
       "  \"contains(('best', 'united'))\": False,\n",
       "  \"contains(('car', 'seat'))\": False,\n",
       "  \"contains(('delayed', 'flights'))\": False,\n",
       "  \"contains(('departure', 'time'))\": False,\n",
       "  \"contains(('flight', 'today'))\": False,\n",
       "  \"contains(('get', 'tickets'))\": False,\n",
       "  \"contains(('ground', 'crew'))\": False,\n",
       "  \"contains(('guys', 'rock'))\": False,\n",
       "  \"contains(('help', 'us'))\": False,\n",
       "  \"contains(('hours', 'ago'))\": False,\n",
       "  \"contains(('new', 'flight'))\": False,\n",
       "  \"contains(('non', 'stop'))\": False,\n",
       "  \"contains(('please', 'follow'))\": False,\n",
       "  \"contains(('service', 'JetBlue'))\": False,\n",
       "  \"contains(('though', 'united'))\": False,\n",
       "  \"contains(('two', 'hours'))\": False,\n",
       "  \"contains(('united', 'If'))\": False,\n",
       "  \"contains(('united', 'Not'))\": False,\n",
       "  \"contains(('united', 'So'))\": False,\n",
       "  \"contains(('united', 'This'))\": False,\n",
       "  \"contains(('united', 'united'))\": False,\n",
       "  \"contains(('weeks', 'ago'))\": False,\n",
       "  \"contains(('American', 'Airlines'))\": False,\n",
       "  \"contains(('AmericanAir', 'Flight'))\": False,\n",
       "  \"contains(('AmericanAir', 'Hi'))\": False,\n",
       "  \"contains(('Cancelled', 'Flights'))\": False,\n",
       "  \"contains(('DestinationDragons', 'united'))\": False,\n",
       "  \"contains(('Great', 'job'))\": False,\n",
       "  \"contains(('Great', 'service'))\": False,\n",
       "  \"contains(('JetBlue', 'great'))\": False,\n",
       "  \"contains(('JetBlue', 'yes'))\": False,\n",
       "  \"contains(('SouthwestAir', 'Hi'))\": False,\n",
       "  \"contains(('SouthwestAir', 'Imaginedragons'))\": False,\n",
       "  \"contains(('SouthwestAir', 'please'))\": False,\n",
       "  \"contains(('That', 'would'))\": False,\n",
       "  \"contains(('USAirways', 'Thanks'))\": False,\n",
       "  \"contains(('VirginAmerica', 'ladygaga'))\": False,\n",
       "  \"contains(('airline', 'ever'))\": False,\n",
       "  \"contains(('back', 'home'))\": False,\n",
       "  \"contains(('baggage', 'fees'))\": False,\n",
       "  \"contains(('call', 'center'))\": False,\n",
       "  \"contains(('cust', 'service'))\": False,\n",
       "  \"contains(('ever', 'united'))\": False,\n",
       "  \"contains(('finally', 'got'))\": False,\n",
       "  \"contains(('first', 'flight'))\": False,\n",
       "  \"contains(('flight', 'USAirways'))\": False,\n",
       "  \"contains(('flight', 'experience'))\": False,\n",
       "  \"contains(('go', 'back'))\": False,\n",
       "  \"contains(('great', 'service'))\": False,\n",
       "  \"contains(('hour', 'flight'))\": False,\n",
       "  \"contains(('international', 'flight'))\": False,\n",
       "  \"contains(('ladygaga', 'carrieunderwood'))\": False,\n",
       "  \"contains(('long', 'time'))\": False,\n",
       "  \"contains(('look', 'forward'))\": False,\n",
       "  \"contains(('never', 'fly'))\": False,\n",
       "  \"contains(('plane', 'united'))\": False,\n",
       "  \"contains(('right', 'united'))\": False,\n",
       "  \"contains(('service', 'today'))\": False,\n",
       "  \"contains(('status', 'match'))\": False,\n",
       "  \"contains(('travel', 'advisory'))\": False,\n",
       "  \"contains(('united', 'Do'))\": False,\n",
       "  \"contains(('united', 'Is'))\": False,\n",
       "  \"contains(('united', 'Please'))\": False,\n",
       "  \"contains(('united', 'Will'))\": False,\n",
       "  \"contains(('united', 'really'))\": False,\n",
       "  \"contains(('us', 'know'))\": False,\n",
       "  \"contains(('yes', 'please'))\": False,\n",
       "  \"contains(('American', 'http'))\": False,\n",
       "  \"contains(('AmericanAir', 'Can'))\": False,\n",
       "  \"contains(('Customer', 'Service'))\": False,\n",
       "  \"contains(('Flight', 'united'))\": False,\n",
       "  \"contains(('Just', 'got'))\": False,\n",
       "  \"contains(('Las', 'Vegas'))\": False,\n",
       "  \"contains(('Looks', 'like'))\": False,\n",
       "  \"contains(('New', 'York'))\": False,\n",
       "  \"contains(('No', 'worries'))\": False,\n",
       "  \"contains(('Palm', 'Springs'))\": False,\n",
       "  \"contains(('Republican', 'American'))\": False,\n",
       "  \"contains(('San', 'Francisco'))\": False,\n",
       "  \"contains(('San', 'Juan'))\": False,\n",
       "  \"contains(('SouthwestAir', 'Any'))\": False,\n",
       "  \"contains(('SouthwestAir', 'How'))\": False,\n",
       "  \"contains(('SouthwestAir', 'Is'))\": False,\n",
       "  \"contains(('SouthwestAir', 'My'))\": False,\n",
       "  \"contains(('SouthwestAir', 'oh'))\": False,\n",
       "  \"contains(('SouthwestAir', 'sent'))\": False,\n",
       "  \"contains(('Street', 'Waterbury'))\": False,\n",
       "  \"contains(('Thank', 'You'))\": False,\n",
       "  \"contains(('USAirways', 'How'))\": False,\n",
       "  \"contains(('USAirways', 'please'))\": False,\n",
       "  \"contains(('VirginAmerica', 'Thanks'))\": False,\n",
       "  \"contains(('VirginAmerica', 'You'))\": False,\n",
       "  \"contains(('Waterbury', 'Republican'))\": False,\n",
       "  \"contains(('airport', 'united'))\": False,\n",
       "  \"contains(('back', 'united'))\": False,\n",
       "  \"contains(('better', 'united'))\": False,\n",
       "  \"contains(('customer', 'united'))\": False,\n",
       "  \"contains(('economy', 'plus'))\": False,\n",
       "  \"contains(('favorite', 'airline'))\": False,\n",
       "  \"contains(('fly', 'united'))\": False,\n",
       "  \"contains(('follow', 'back'))\": False,\n",
       "  \"contains(('gate', 'united'))\": False,\n",
       "  \"contains(('get', 'back'))\": False,\n",
       "  \"contains(('got', 'Cancelled'))\": False,\n",
       "  \"contains(('got', 'us'))\": False,\n",
       "  \"contains(('guys', 'united'))\": False,\n",
       "  \"contains(('help', 'AmericanAir'))\": False,\n",
       "  \"contains(('help', 'JetBlue'))\": False,\n",
       "  \"contains(('hours', 'united'))\": False,\n",
       "  \"contains(('last', 'name'))\": False,\n",
       "  \"contains(('last', 'year'))\": False,\n",
       "  \"contains(('mileage', 'plus'))\": False,\n",
       "  \"contains(('months', 'ago'))\": False,\n",
       "  \"contains(('need', 'assistance'))\": False,\n",
       "  \"contains(('new', 'plane'))\": False,\n",
       "  \"contains(('next', 'week'))\": False,\n",
       "  \"contains(('see', 'Imaginedragons'))\": False,\n",
       "  \"contains(('seems', 'like'))\": False,\n",
       "  \"contains(('sent', 'united'))\": False,\n",
       "  \"contains(('service', 'SouthwestAir'))\": False,\n",
       "  \"contains(('service', 'desk'))\": False,\n",
       "  \"contains(('service', 'rep'))\": False,\n",
       "  \"contains(('several', 'times'))\": False,\n",
       "  \"contains(('social', 'media'))\": False,\n",
       "  \"contains(('still', 'sitting'))\": False,\n",
       "  \"contains(('taking', 'care'))\": False,\n",
       "  \"contains(('two', 'days'))\": False,\n",
       "  \"contains(('united', 'Cancelled'))\": False,\n",
       "  \"contains(('united', 'On'))\": False,\n",
       "  \"contains(('united', 'customer'))\": False,\n",
       "  \"contains(('united', 'hi'))\": False,\n",
       "  \"contains(('united', 'nope'))\": False,\n",
       "  \"contains(('united', 'tried'))\": False,\n",
       "  \"contains(('way', 'united'))\": False,\n",
       "  \"contains(('year', 'old'))\": False,\n",
       "  \"contains(('1st', 'time'))\": False,\n",
       "  \"contains(('Airport', 'http'))\": False,\n",
       "  \"contains(('AmericanAir', 'You'))\": False,\n",
       "  \"contains(('AmericanAir', 'great'))\": False,\n",
       "  \"contains(('AmericanAir', 'please'))\": False,\n",
       "  \"contains(('Any', 'idea'))\": False,\n",
       "  \"contains(('Cancelled', 'Flightling'))\": False,\n",
       "  \"contains(('Customer', 'service'))\": False,\n",
       "  \"contains(('DestinationDragons', 'SouthwestAir'))\": False,\n",
       "  \"contains(('Flightled', 'flights'))\": False,\n",
       "  \"contains(('Flightled', 'united'))\": False,\n",
       "  \"contains(('Good', 'luck'))\": False,\n",
       "  \"contains(('Imagine', 'Dragons'))\": False,\n",
       "  \"contains(('Is', 'flight'))\": False,\n",
       "  \"contains(('JetBlue', 'Flight'))\": False,\n",
       "  \"contains(('JetBlue', 'Just'))\": False,\n",
       "  \"contains(('JetBlue', 'That'))\": False,\n",
       "  \"contains(('JetBlue', 'ok'))\": False,\n",
       "  \"contains(('My', 'wife'))\": False,\n",
       "  \"contains(('Not', 'sure'))\": False,\n",
       "  \"contains(('Please', 'follow'))\": False,\n",
       "  \"contains(('SouthwestAir', 'Do'))\": False,\n",
       "  \"contains(('SouthwestAir', 'Great'))\": False,\n",
       "  \"contains(('SouthwestAir', 'When'))\": False,\n",
       "  \"contains(('SouthwestAir', 'got'))\": False,\n",
       "  \"contains(('SouthwestAir', 'great'))\": False,\n",
       "  \"contains(('Thx', 'united'))\": False,\n",
       "  \"contains(('USAirways', 'Can'))\": False,\n",
       "  \"contains(('airline', 'JetBlue'))\": False,\n",
       "  \"contains(('best', 'customer'))\": False,\n",
       "  \"contains(('boarding', 'passes'))\": False,\n",
       "  \"contains(('checked', 'baggage'))\": False,\n",
       "  \"contains(('customer', 'relations'))\": False,\n",
       "  \"contains(('days', 'united'))\": False,\n",
       "  \"contains(('first', 'united'))\": False,\n",
       "  \"contains(('flight', 'delayed'))\": False,\n",
       "  \"contains(('flight', 'time'))\": False,\n",
       "  \"contains(('flight', 'without'))\": False,\n",
       "  \"contains(('flight', 'yesterday'))\": False,\n",
       "  \"contains(('flights', 'today'))\": False,\n",
       "  \"contains(('fly', 'United'))\": False,\n",
       "  \"contains(('great', 'crew'))\": False,\n",
       "  \"contains(('half', 'hour'))\": False,\n",
       "  \"contains(('help', 'VirginAmerica'))\": False,\n",
       "  \"contains(('home', 'today'))\": False,\n",
       "  \"contains(('hotel', 'room'))\": False,\n",
       "  \"contains(('info', 'united'))\": False,\n",
       "  \"contains(('last', 'month'))\": False,\n",
       "  \"contains(('last', 'time'))\": False,\n",
       "  \"contains(('lol', 'united'))\": False,\n",
       "  \"contains(('lost', 'bag'))\": False,\n",
       "  \"contains(('luggage', 'united'))\": False,\n",
       "  \"contains(('maintenance', 'issues'))\": False,\n",
       "  \"contains(('middle', 'seat'))\": False,\n",
       "  \"contains(('minute', 'wait'))\": False,\n",
       "  \"contains(('miss', 'connection'))\": False,\n",
       "  \"contains(('missed', 'connection'))\": False,\n",
       "  \"contains(('never', 'got'))\": False,\n",
       "  \"contains(('one', 'day'))\": False,\n",
       "  \"contains(('phone', 'united'))\": False,\n",
       "  \"contains(('please', 'JetBlue'))\": False,\n",
       "  \"contains(('please', 'passengers'))\": False,\n",
       "  \"contains(('power', 'outlets'))\": False,\n",
       "  \"contains(('prompt', 'response'))\": False,\n",
       "  \"contains(('reLate', 'Flightd'))\": False,\n",
       "  \"contains(('right', 'balance'))\": False,\n",
       "  \"contains(('service', 'ever'))\": False,\n",
       "  \"contains(('taken', 'care'))\": False,\n",
       "  \"contains(('terrible', 'customer'))\": False,\n",
       "  \"contains(('time', 'JetBlue'))\": False,\n",
       "  \"contains(('time', 'amp'))\": False,\n",
       "  \"contains(('today', 'JetBlue'))\": False,\n",
       "  \"contains(('tonight', 'united'))\": False,\n",
       "  \"contains(('trip', 'united'))\": False,\n",
       "  \"contains(('united', 'also'))\": False,\n",
       "  \"contains(('united', 'hey'))\": False,\n",
       "  \"contains(('united', 'seriously'))\": False,\n",
       "  \"contains(('via', 'Twitter'))\": False,\n",
       "  \"contains(('wait', 'times'))\": False,\n",
       "  \"contains(('weather', 'delay'))\": False,\n",
       "  \"contains(('work', 'united'))\": False,\n",
       "  \"contains(('would', 'go'))\": False,\n",
       "  \"contains(('would', 'make'))\": False,\n",
       "  \"contains(('yr', 'old'))\": False,\n",
       "  \"contains(('Airlines', 'united'))\": False,\n",
       "  \"contains(('Airways', 'Corporation'))\": False,\n",
       "  \"contains(('AmericanAir', 'USAirways'))\": False,\n",
       "  \"contains(('AmericanAir', 'dfwairport'))\": False,\n",
       "  \"contains(('Any', 'help'))\": False,\n",
       "  \"contains(('Flight', 'flights'))\": False,\n",
       "  \"contains(('Flighted', 'flight'))\": False,\n",
       "  \"contains(('Flighted', 'united'))\": False,\n",
       "  \"contains(('Flightr', 'united'))\": False,\n",
       "  \"contains(('Imaginedragons', 'DestinationDragons'))\": False,\n",
       "  \"contains(('Imaginedragons', 'show'))\": False,\n",
       "  \"contains(('It', 'would'))\": False,\n",
       "  \"contains(('JetBlue', 'We'))\": False,\n",
       "  \"contains(('JetBlue', 'hi'))\": False,\n",
       "  \"contains(('JetBlue', 'united'))\": False,\n",
       "  \"contains(('Just', 'wanted'))\": False,\n",
       "  \"contains(('Love', 'Field'))\": False,\n",
       "  \"contains(('Not', 'cool'))\": False,\n",
       "  \"contains(('Please', 'let'))\": False,\n",
       "  \"contains(('SouthwestAir', 'Flight'))\": False,\n",
       "  \"contains(('SouthwestAir', 'That'))\": False,\n",
       "  \"contains(('SouthwestAir', 'flying'))\": False,\n",
       "  \"contains(('SouthwestAir', 'would'))\": False,\n",
       "  \"contains(('USAirways', 'yes'))\": False,\n",
       "  \"contains(('United', 'Club'))\": False,\n",
       "  \"contains(('VirginAmerica', 'Is'))\": False,\n",
       "  \"contains(('VirginAmerica', 'thank'))\": False,\n",
       "  \"contains(('We', 'hope'))\": False,\n",
       "  \"contains(('With', 'New'))\": False,\n",
       "  \"contains(('Your', 'airline'))\": False,\n",
       "  \"contains(('Your', 'customer'))\": False,\n",
       "  \"contains(('Your', 'website'))\": False,\n",
       "  \"contains(('airline', 'SouthwestAir'))\": False,\n",
       "  \"contains(('airlines', 'united'))\": False,\n",
       "  \"contains(('amazing', 'customer'))\": False,\n",
       "  \"contains(('among', 'teens'))\": False,\n",
       "  \"contains(('another', 'plane'))\": False,\n",
       "  \"contains(('appreciated', 'JetBlue'))\": False,\n",
       "  \"contains(('appreciated', 'united'))\": False,\n",
       "  \"contains(('avgeek', 'united'))\": False,\n",
       "  \"contains(('awesome', 'Thanks'))\": False,\n",
       "  \"contains(('awesome', 'flight'))\": False,\n",
       "  \"contains(('bag', 'SouthwestAir'))\": False,\n",
       "  \"contains(('business', 'class'))\": False,\n",
       "  \"contains(('cabin', 'crew'))\": False,\n",
       "  \"contains(('could', 'use'))\": False,\n",
       "  \"contains(('days', 'ago'))\": False,\n",
       "  \"contains(('death', 'among'))\": False,\n",
       "  \"contains(('delay', 'JetBlue'))\": False,\n",
       "  \"contains(('delays', 'united'))\": False,\n",
       "  \"contains(('different', 'flight'))\": False,\n",
       "  \"contains(('domestic', 'flight'))\": False,\n",
       "  \"contains(('email', 'united'))\": False,\n",
       "  \"contains(('empty', 'seats'))\": False,\n",
       "  \"contains(('error', 'message'))\": False,\n",
       "  \"contains(('existing', 'reservation'))\": False,\n",
       "  \"contains(('exit', 'row'))\": False,\n",
       "  \"contains(('experience', 'ever'))\": False,\n",
       "  \"contains(('feel', 'like'))\": False,\n",
       "  \"contains(('first', 'place'))\": False,\n",
       "  \"contains(('flight', 'AmericanAir'))\": False,\n",
       "  \"contains(('flight', 'Thanks'))\": False,\n",
       "  \"contains(('flight', 'ever'))\": False,\n",
       "  \"contains(('flight', 'got'))\": False,\n",
       "  \"contains(('flight', 'number'))\": False,\n",
       "  \"contains(('flight', 'status'))\": False,\n",
       "  \"contains(('flight', 'w'))\": False,\n",
       "  \"contains(('flights', 'SouthwestAir'))\": False,\n",
       "  \"contains(('flying', 'united'))\": False,\n",
       "  \"contains(('gate', 'changes'))\": False,\n",
       "  \"contains(('getting', 'us'))\": False,\n",
       "  \"contains(('great', 'AmericanAir'))\": False,\n",
       "  \"contains(('ground', 'staff'))\": False,\n",
       "  \"contains(('help', 'USAirways'))\": False,\n",
       "  \"contains(('helpful', 'SouthwestAir'))\": False,\n",
       "  \"contains(('home', 'tonight'))\": False,\n",
       "  \"contains(('hour', 'Late'))\": False,\n",
       "  \"contains(('hrs', 'Late'))\": False,\n",
       "  \"contains(('jet', 'blue'))\": False,\n",
       "  \"contains(('leading', 'cause'))\": False,\n",
       "  \"contains(('love', 'flying'))\": False,\n",
       "  \"contains(('many', 'times'))\": False,\n",
       "  \"contains(('minutes', 'ago'))\": False,\n",
       "  \"contains(('ok', 'thank'))\": False,\n",
       "  \"contains(('ok', 'thanks'))\": False,\n",
       "  \"contains(('please', 'Thanks'))\": False,\n",
       "  \"contains(('please', 'please'))\": False,\n",
       "  \"contains(('policy', 'united'))\": False,\n",
       "  \"contains(('red', 'eye'))\": False,\n",
       "  \"contains(('refund', 'united'))\": False,\n",
       "  \"contains(('reservation', 'SouthwestAir'))\": False,\n",
       "  \"contains(('reservation', 'united'))\": False,\n",
       "  \"contains(('scavenger', 'hunt'))\": False,\n",
       "  \"contains(('seat', 'united'))\": False,\n",
       "  \"contains(('seats', 'united'))\": False,\n",
       "  \"contains(('second', 'leading'))\": False,\n",
       "  \"contains(('second', 'time'))\": False,\n",
       "  \"contains(('service', 'amp'))\": False,\n",
       "  \"contains(('service', 'team'))\": False,\n",
       "  \"contains(('soon', 'SouthwestAir'))\": False,\n",
       "  \"contains(('soon', 'united'))\": False,\n",
       "  \"contains(('super', 'helpful'))\": False,\n",
       "  \"contains(('take', 'care'))\": False,\n",
       "  \"contains(('tickets', 'united'))\": False,\n",
       "  \"contains(('today', 'Thanks'))\": False,\n",
       "  \"contains(('tomorrow', 'SouthwestAir'))\": False,\n",
       "  \"contains(('tonight', 'JetBlue'))\": False,\n",
       "  \"contains(('tonight', 'SouthwestAir'))\": False,\n",
       "  \"contains(('took', 'care'))\": False,\n",
       "  \"contains(('u', 'guys'))\": False,\n",
       "  \"contains(('united', 'But'))\": False,\n",
       "  \"contains(('united', 'Great'))\": False,\n",
       "  \"contains(('united', 'JetBlue'))\": False,\n",
       "  \"contains(('united', 'Nope'))\": False,\n",
       "  \"contains(('united', 'When'))\": False,\n",
       "  \"contains(('united', 'already'))\": False,\n",
       "  \"contains(('united', 'flt'))\": False,\n",
       "  \"contains(('united', 'great'))\": False,\n",
       "  \"contains(('united', 'need'))\": False,\n",
       "  \"contains(('united', 'never'))\": False,\n",
       "  \"contains(('united', 'oh'))\": False,\n",
       "  \"contains(('united', 'sitting'))\": False,\n",
       "  \"contains(('united', 'staralliance'))\": False,\n",
       "  \"contains(('united', 'thnx'))\": False,\n",
       "  \"contains(('us', 'home'))\": False,\n",
       "  \"contains(('worst', 'customer'))\": False,\n",
       "  \"contains(('would', 'appreciate'))\": False,\n",
       "  \"contains(('would', 'rather'))\": False,\n",
       "  \"contains(('1st', 'flight'))\": False,\n",
       "  \"contains(('2nd', 'time'))\": False,\n",
       "  \"contains(('Airport', 'snow'))\": False,\n",
       "  \"contains(('AmericanAir', 'Do'))\": False,\n",
       "  \"contains(('AmericanAir', 'flight'))\": False,\n",
       "  \"contains(('AmericanAir', 'got'))\": False,\n",
       "  \"contains(('AmericanAir', 'ok'))\": False,\n",
       "  \"contains(('AmericanAir', 'well'))\": False,\n",
       "  \"contains(('Big', 'thanks'))\": False,\n",
       "  \"contains(('Can', 'someone'))\": False,\n",
       "  \"contains(('Cancelled', 'Flightations'))\": False,\n",
       "  \"contains(('DestinationDragons', 'http'))\": False,\n",
       "  \"contains(('Digital', 'Journal'))\": False,\n",
       "  \"contains(('First', 'Class'))\": False,\n",
       "  \"contains(('Flight', 'SouthwestAir'))\": False,\n",
       "  \"contains(('Flight', 'crew'))\": False,\n",
       "  \"contains(('FlyTPA', 'following'))\": False,\n",
       "  \"contains(('Fort', 'Lauderdale'))\": False,\n",
       "  \"contains(('Great', 'thank'))\": False,\n",
       "  \"contains(('Help', 'united'))\": False,\n",
       "  \"contains(('Hi', 'guys'))\": False,\n",
       "  \"contains(('How', 'many'))\": False,\n",
       "  \"contains(('In', 'Flight'))\": False,\n",
       "  \"contains(('Jet', 'Blue'))\": False,\n",
       "  \"contains(('JetBlue', 'Can'))\": False,\n",
       "  \"contains(('JetBlue', 'Great'))\": False,\n",
       "  \"contains(('JetBlue', 'Hi'))\": False,\n",
       "  \"contains(('JetBlue', 'What'))\": False,\n",
       "  \"contains(('JetBlue', 'okay'))\": False,\n",
       "  \"contains(('JetBlue', 'well'))\": False,\n",
       "  \"contains(('Just', 'landed'))\": False,\n",
       "  \"contains(('Late', 'Flightst'))\": False,\n",
       "  \"contains(('Love', 'flying'))\": False,\n",
       "  \"contains(('Much', 'appreciated'))\": False,\n",
       "  \"contains(('My', 'bag'))\": False,\n",
       "  \"contains(('My', 'flight'))\": False,\n",
       "  \"contains(('Never', 'got'))\": False,\n",
       "  \"contains(('News', 'http'))\": False,\n",
       "  \"contains(('No', 'one'))\": False,\n",
       "  \"contains(('Of', 'course'))\": False,\n",
       "  \"contains(('SouthwestAir', 'Are'))\": False,\n",
       "  \"contains(('SouthwestAir', 'Hey'))\": False,\n",
       "  \"contains(('SouthwestAir', 'So'))\": False,\n",
       "  \"contains(('SouthwestAir', 'Thx'))\": False,\n",
       "  \"contains(('SouthwestAir', 'Your'))\": False,\n",
       "  \"contains(('SouthwestAir', 'flight'))\": False,\n",
       "  \"contains(('SouthwestAir', 'give'))\": False,\n",
       "  \"contains(('SouthwestAir', 'still'))\": False,\n",
       "  \"contains(('SouthwestAir', 'sure'))\": False,\n",
       "  \"contains(('Star', 'Alliance'))\": False,\n",
       "  \"contains(('Thank', 'u'))\": False,\n",
       "  \"contains(('Thanks', 'David'))\": False,\n",
       "  \"contains(('Thanks', 'United'))\": False,\n",
       "  \"contains(('Too', 'Late'))\": False,\n",
       "  \"contains(('USAirways', 'Yes'))\": False,\n",
       "  \"contains(('USAirways', 'flight'))\": False,\n",
       "  \"contains(('Virgin', 'America'))\": False,\n",
       "  \"contains(('VirginAmerica', 'Your'))\": False,\n",
       "  \"contains(('You', 'need'))\": False,\n",
       "  \"contains(('You', 'united'))\": False,\n",
       "  \"contains(('Your', 'crew'))\": False,\n",
       "  \"contains(('actually', 'get'))\": False,\n",
       "  \"contains(('airline', 'AmericanAir'))\": False,\n",
       "  \"contains(('amazing', 'united'))\": False,\n",
       "  \"contains(('available', 'united'))\": False,\n",
       "  \"contains(('avgeek', 'http'))\": False,\n",
       "  \"contains(('away', 'SouthwestAir'))\": False,\n",
       "  \"contains(('back', 'SouthwestAir'))\": False,\n",
       "  \"contains(('bad', 'united'))\": False,\n",
       "  \"contains(('best', 'flight'))\": False,\n",
       "  \"contains(('best', 'friend'))\": False,\n",
       "  \"contains(('board', 'united'))\": False,\n",
       "  \"contains(('business', 'JetBlue'))\": False,\n",
       "  \"contains(('change', 'fees'))\": False,\n",
       "  \"contains(('class', 'seat'))\": False,\n",
       "  \"contains(('confirmation', 'email'))\": False,\n",
       "  \"contains(('connection', 'united'))\": False,\n",
       "  \"contains(('cross', 'country'))\": False,\n",
       "  \"contains(('customer', 'experience'))\": False,\n",
       "  \"contains(('day', 'Late'))\": False,\n",
       "  \"contains(('de', 'ice'))\": False,\n",
       "  \"contains(('delay', 'united'))\": False,\n",
       "  \"contains(('e', 'mail'))\": False,\n",
       "  \"contains(('every', 'week'))\": False,\n",
       "  \"contains(('excellent', 'customer'))\": False,\n",
       "  \"contains(('exchange', 'rate'))\": False,\n",
       "  \"contains(('final', 'destination'))\": False,\n",
       "  \"contains(('flight', 'How'))\": False,\n",
       "  \"contains(('flight', 'VirginAmerica'))\": False,\n",
       "  \"contains(('flight', 'back'))\": False,\n",
       "  \"contains(('flight', 'http'))\": False,\n",
       "  \"contains(('flight', 'voucher'))\": False,\n",
       "  \"contains(('fly', 'Southwest'))\": False,\n",
       "  \"contains(('flying', 'United'))\": False,\n",
       "  \"contains(('flying', 'experience'))\": False,\n",
       "  \"contains(('following', 'flight'))\": False,\n",
       "  \"contains(('free', 'wifi'))\": False,\n",
       "  \"contains(('frequent', 'flyer'))\": False,\n",
       "  \"contains(('future', 'united'))\": False,\n",
       "  \"contains(('getting', 'Cancelled'))\": False,\n",
       "  \"contains(('getting', 'back'))\": False,\n",
       "  \"contains(('go', 'see'))\": False,\n",
       "  \"contains(('go', 'united'))\": False,\n",
       "  \"contains(('going', 'back'))\": False,\n",
       "  \"contains(('great', 'thanks'))\": False,\n",
       "  \"contains(('great', 'united'))\": False,\n",
       "  \"contains(('guys', 'JetBlue'))\": False,\n",
       "  \"contains(('guys', 'suck'))\": False,\n",
       "  \"contains(('hrs', 'ago'))\": False,\n",
       "  \"contains(('imagine', 'dragons'))\": False,\n",
       "  \"contains(('info', 'JetBlue'))\": False,\n",
       "  \"contains(('issues', 'united'))\": False,\n",
       "  \"contains(('job', 'united'))\": False,\n",
       "  \"contains(('keep', 'getting'))\": False,\n",
       "  \"contains(('keeping', 'us'))\": False,\n",
       "  \"contains(('last', 'minute'))\": False,\n",
       "  \"contains(('left', 'something'))\": False,\n",
       "  \"contains(('life', 'JetBlue'))\": False,\n",
       "  \"contains(('long', 'day'))\": False,\n",
       "  \"contains(('long', 'wait'))\": False,\n",
       "  \"contains(('look', 'like'))\": False,\n",
       "  \"contains(('love', 'JetBlue'))\": False,\n",
       "  \"contains(('luggage', 'SouthwestAir'))\": False,\n",
       "  \"contains(('many', 'people'))\": False,\n",
       "  \"contains(('mechanical', 'problems'))\": False,\n",
       "  \"contains(('miles', 'united'))\": False,\n",
       "  \"contains(('min', 'Late'))\": False,\n",
       "  \"contains(('missing', 'bag'))\": False,\n",
       "  \"contains(('morning', 'SouthwestAir'))\": False,\n",
       "  \"contains(('morning', 'united'))\": False,\n",
       "  \"contains(('much', 'appreciated'))\": False,\n",
       "  \"contains(('never', 'flying'))\": False,\n",
       "  \"contains(('new', 'routes'))\": False,\n",
       "  \"contains(('non', 'existent'))\": False,\n",
       "  \"contains(('nothing', 'united'))\": False,\n",
       "  \"contains(('one', 'hour'))\": False,\n",
       "  \"contains(('online', 'USAirways'))\": False,\n",
       "  \"contains(('online', 'united'))\": False,\n",
       "  \"contains(('option', 'united'))\": False,\n",
       "  \"contains(('original', 'flight'))\": False,\n",
       "  \"contains(('pass', 'united'))\": False,\n",
       "  \"contains(('people', 'working'))\": False,\n",
       "  \"contains(('place', 'united'))\": False,\n",
       "  \"contains(('plane', 'back'))\": False,\n",
       "  \"contains(('planes', 'united'))\": False,\n",
       "  \"contains(('please', 'SouthwestAir'))\": False,\n",
       "  \"contains(('please', 'give'))\": False,\n",
       "  \"contains(('please', 'tell'))\": False,\n",
       "  \"contains(('poor', 'customer'))\": False,\n",
       "  \"contains(('quick', 'reply'))\": False,\n",
       "  \"contains(('removal', 'method'))\": False,\n",
       "  \"contains(('rental', 'car'))\": False,\n",
       "  \"contains(('return', 'ticket'))\": False,\n",
       "  \"contains(('right', 'thing'))\": False,\n",
       "  \"contains(('rock', 'united'))\": False,\n",
       "  \"contains(('room', 'united'))\": False,\n",
       "  \"contains(('sent', 'Thanks'))\": False,\n",
       "  \"contains(('service', 'Thank'))\": False,\n",
       "  \"contains(('service', 'VirginAmerica'))\": False,\n",
       "  \"contains(('service', 'agent'))\": False,\n",
       "  \"contains(('service', 'experience'))\": False,\n",
       "  \"contains(('service', 'sucks'))\": False,\n",
       "  \"contains(('snow', 'removal'))\": False,\n",
       "  \"contains(('snow', 'storm'))\": False,\n",
       "  \"contains(('someone', 'please'))\": False,\n",
       "  \"contains(('start', 'flying'))\": False,\n",
       "  \"contains(('thx', 'united'))\": False,\n",
       "  \"contains(('ticket', 'agent'))\": False,\n",
       "  \"contains(('ticket', 'united'))\": False,\n",
       "  \"contains(('told', 'us'))\": False,\n",
       "  \"contains(('tomorrow', 'VirginAmerica'))\": False,\n",
       "  \"contains(('two', 'different'))\": False,\n",
       "  \"contains(('two', 'weeks'))\": False,\n",
       "  \"contains(('united', 'Okay'))\": False,\n",
       "  \"contains(('united', 'Stuck'))\": False,\n",
       "  \"contains(('united', 'There'))\": False,\n",
       "  \"contains(('united', 'They'))\": False,\n",
       "  \"contains(('united', 'UnitedAirlines'))\": False,\n",
       "  \"contains(('united', 'annricord'))\": False,\n",
       "  \"contains(('united', 'booked'))\": False,\n",
       "  \"contains(('united', 'delayed'))\": False,\n",
       "  \"contains(('united', 'done'))\": False,\n",
       "  \"contains(('united', 'even'))\": False,\n",
       "  \"contains(('united', 'gg8929'))\": False,\n",
       "  \"contains(('united', 'good'))\": False,\n",
       "  \"contains(('united', 'look'))\": False,\n",
       "  \"contains(('united', 'lost'))\": False,\n",
       "  \"contains(('united', 'nice'))\": False,\n",
       "  \"contains(('united', 'sent'))\": False,\n",
       "  \"contains(('via', 'email'))\": False,\n",
       "  \"contains(('way', 'JetBlue'))\": False,\n",
       "  \"contains(('weather', 'reLate'))\": False,\n",
       "  \"contains(('work', 'folks'))\": False,\n",
       "  \"contains(('working', 'hard'))\": False,\n",
       "  \"contains(('year', 'http'))\": False,\n",
       "  \"contains(('yes', 'yes'))\": False,\n",
       "  \"contains(('3d', 'embossed'))\": False,\n",
       "  \"contains(('3rd', 'party'))\": False,\n",
       "  \"contains(('About', 'Summer'))\": False,\n",
       "  \"contains(('AmericanAir', 'Aww'))\": False,\n",
       "  \"contains(('AmericanAir', 'Great'))\": False,\n",
       "  \"contains(('AmericanAir', 'My'))\": False,\n",
       "  \"contains(('AmericanAir', 'No'))\": False,\n",
       "  \"contains(('AmericanAir', 'These'))\": False,\n",
       "  \"contains(('AmericanAir', 'We'))\": False,\n",
       "  \"contains(('AmericanAir', 'What'))\": False,\n",
       "  \"contains(('AmericanAir', 'When'))\": False,\n",
       "  \"contains(('AmericanAir', 'Yes'))\": False,\n",
       "  \"contains(('AmericanAir', 'awesome'))\": False,\n",
       "  \"contains(('AmericanAir', 'united'))\": False,\n",
       "  \"contains(('Another', 'reason'))\": False,\n",
       "  \"contains(('Apple', 'Pay'))\": False,\n",
       "  \"contains(('Atlanta', 'show'))\": False,\n",
       "  \"contains(('Booking', 'Problemss'))\": False,\n",
       "  \"contains(('CheapFlights', 'FareCompare'))\": False,\n",
       "  \"contains(('Chicago', 'united'))\": False,\n",
       "  \"contains(('Companion', 'Pass'))\": False,\n",
       "  \"contains(('Customer', 'Care'))\": False,\n",
       "  \"contains(('Daily', 'http'))\": False,\n",
       "  \"contains(('Delta', 'united'))\": False,\n",
       "  \"contains(('DestinationDragons', 'Imaginedragons'))\": False,\n",
       "  \"contains(('DestinationDragons', 'VirginAmerica'))\": False,\n",
       "  \"contains(('Dividend', 'Miles'))\": False,\n",
       "  \"contains(('Eastern', 'Airlines'))\": False,\n",
       "  \"contains(('F2LFULCbQ7', 'let'))\": False,\n",
       "  \"contains(('Flight', 'Access'))\": False,\n",
       "  \"contains(('Flight', 'attendant'))\": False,\n",
       "  \"contains(('Flighted', 'flights'))\": False,\n",
       "  \"contains(('Flightled', 'SouthwestAir'))\": False,\n",
       "  \"contains(('Flightled', 'due'))\": False,\n",
       "  \"contains(('Flightr', 'still'))\": False,\n",
       "  \"contains(('Flightr', 'today'))\": False,\n",
       "  \"contains(('Gate', 'agent'))\": False,\n",
       "  \"contains(('Good', 'morning'))\": False,\n",
       "  \"contains(('Grandma', 'Ella'))\": False,\n",
       "  \"contains(('Great', 'customer'))\": False,\n",
       "  \"contains(('Help', 'SouthwestAir'))\": False,\n",
       "  \"contains(('How', 'come'))\": False,\n",
       "  \"contains(('It', 'looks'))\": False,\n",
       "  \"contains(('JetBlue', 'Awesome'))\": False,\n",
       "  \"contains(('JetBlue', 'Has'))\": False,\n",
       "  \"contains(('JetBlue', 'Hey'))\": False,\n",
       "  \"contains(('JetBlue', 'If'))\": False,\n",
       "  \"contains(('JetBlue', 'It'))\": False,\n",
       "  \"contains(('JetBlue', 'No'))\": False,\n",
       "  \"contains(('JetBlue', 'The'))\": False,\n",
       "  \"contains(('JetBlue', 'When'))\": False,\n",
       "  \"contains(('JetBlue', 'good'))\": False,\n",
       "  \"contains(('JetBlue', 'oh'))\": False,\n",
       "  \"contains(('Late', 'Flightly'))\": False,\n",
       "  \"contains(('Many', 'thanks'))\": False,\n",
       "  \"contains(('Nantucket', 'Service'))\": False,\n",
       "  \"contains(('Nashville', 'tomorrow'))\": False,\n",
       "  \"contains(('New', 'Nantucket'))\": False,\n",
       "  \"contains(('New', 'Orleans'))\": False,\n",
       "  \"contains(('New', 'marketing'))\": False,\n",
       "  \"contains(('Offer', 'In'))\": False,\n",
       "  \"contains(('On', 'flight'))\": False,\n",
       "  \"contains(('Our', 'flight'))\": False,\n",
       "  \"contains(('Problems', 'united'))\": False,\n",
       "  \"contains(('Punta', 'Cana'))\": False,\n",
       "  \"contains(('Reminder', 'From'))\": False,\n",
       "  \"contains(('San', 'Jose'))\": False,\n",
       "  \"contains(('Short', 'Interest'))\": False,\n",
       "  \"contains(('So', 'excited'))\": False,\n",
       "  \"contains(('So', 'far'))\": False,\n",
       "  \"contains(('Social', 'Media'))\": False,\n",
       "  \"contains(('SouthwestAir', 'All'))\": False,\n",
       "  \"contains(('SouthwestAir', 'Awesome'))\": False,\n",
       "  \"contains(('SouthwestAir', 'DestinationDragons'))\": False,\n",
       "  \"contains(('SouthwestAir', 'Hello'))\": False,\n",
       "  \"contains(('SouthwestAir', 'If'))\": False,\n",
       "  \"contains(('SouthwestAir', 'Southwest'))\": False,\n",
       "  \"contains(('SouthwestAir', 'The'))\": False,\n",
       "  \"contains(('SouthwestAir', 'What'))\": False,\n",
       "  \"contains(('SouthwestAir', 'Yes'))\": False,\n",
       "  \"contains(('SouthwestAir', 'done'))\": False,\n",
       "  \"contains(('SouthwestAir', 'hey'))\": False,\n",
       "  \"contains(('SouthwestAir', 'love'))\": False,\n",
       "  \"contains(('SouthwestAir', 'thx'))\": False,\n",
       "  \"contains(('SouthwestAir', 'trying'))\": False,\n",
       "  \"contains(('St', 'Louis'))\": False,\n",
       "  \"contains(('Summer', 'With'))\": False,\n",
       "  \"contains(('Sunday', 'united'))\": False,\n",
       "  \"contains(('Terrible', 'service'))\": False,\n",
       "  \"contains(('They', 'said'))\": False,\n",
       "  \"contains(('Thinking', 'About'))\": False,\n",
       "  \"contains(('Thx', 'JetBlue'))\": False,\n",
       "  \"contains(('Twitter', 'united'))\": False,\n",
       "  \"contains(('USAirways', 'Flight'))\": False,\n",
       "  \"contains(('USAirways', 'Hi'))\": False,\n",
       "  \"contains(('USAirways', 'Is'))\": False,\n",
       "  \"contains(('USAirways', 'No'))\": False,\n",
       "  \"contains(('USAirways', 'Reminder'))\": False,\n",
       "  \"contains(('USAirways', 'Will'))\": False,\n",
       "  \"contains(('USAirways', 'ok'))\": False,\n",
       "  \"contains(('United', 'What'))\": False,\n",
       "  \"contains(('Vegas', 'event'))\": False,\n",
       "  \"contains(('VirginAmerica', 'Can'))\": False,\n",
       "  \"contains(('VirginAmerica', 'Flight'))\": False,\n",
       "  \"contains(('VirginAmerica', 'hi'))\": False,\n",
       "  \"contains(('VirginAmerica', 'trying'))\": False,\n",
       "  \"contains(('Well', 'done'))\": False,\n",
       "  \"contains(('What', 'gives'))\": False,\n",
       "  \"contains(('What', 'happened'))\": False,\n",
       "  \"contains(('Worst', 'airline'))\": False,\n",
       "  \"contains(('Would', 'love'))\": False,\n",
       "  \"contains(('You', 'got'))\": False,\n",
       "  \"contains(('You', 'know'))\": False,\n",
       "  \"contains(('You', 'really'))\": False,\n",
       "  \"contains(('account', 'united'))\": False,\n",
       "  \"contains(('address', 'please'))\": False,\n",
       "  \"contains(('advance', 'united'))\": False,\n",
       "  \"contains(('afternoon', 'united'))\": False,\n",
       "  \"contains(('air', 'united'))\": False,\n",
       "  \"contains(('airport', 'SouthwestAir'))\": False,\n",
       "  \"contains(('already', 'booked'))\": False,\n",
       "  \"contains(('amp', 'crew'))\": False,\n",
       "  \"contains(('amp', 'got'))\": False,\n",
       "  \"contains(('amp', 'one'))\": False,\n",
       "  \"contains(('another', 'airport'))\": False,\n",
       "  \"contains(('another', 'hour'))\": False,\n",
       "  \"contains(('app', 'says'))\": False,\n",
       "  \"contains(('arrival', 'time'))\": False,\n",
       "  \"contains(('award', 'ticket'))\": False,\n",
       "  \"contains(('awesome', 'united'))\": False,\n",
       "  \"contains(('back', 'JetBlue'))\": False,\n",
       "  \"contains(('bad', 'experience'))\": False,\n",
       "  \"contains(('bag', 'check'))\": False,\n",
       "  \"contains(('bags', 'still'))\": False,\n",
       "  \"contains(('best', 'airlines'))\": False,\n",
       "  \"contains(('best', 'option'))\": False,\n",
       "  \"contains(('better', 'JetBlue'))\": False,\n",
       "  \"contains(('better', 'SouthwestAir'))\": False,\n",
       "  \"contains(('better', 'airline'))\": False,\n",
       "  \"contains(('better', 'service'))\": False,\n",
       "  \"contains(('big', 'thanks'))\": False,\n",
       "  \"contains(('blog', 'http'))\": False,\n",
       "  \"contains(('boarding', 'time'))\": False,\n",
       "  \"contains(('call', 'back'))\": False,\n",
       "  \"contains(('call', 'united'))\": False,\n",
       "  \"contains(('called', 'United'))\": False,\n",
       "  \"contains(('car', 'seats'))\": False,\n",
       "  \"contains(('card', 'holders'))\": False,\n",
       "  \"contains(('case', 'id'))\": False,\n",
       "  \"contains(('change', 'flight'))\": False,\n",
       "  \"contains(('check', 'bags'))\": False,\n",
       "  \"contains(('check', 'ins'))\": False,\n",
       "  \"contains(('chocoLate', 'Flight'))\": False,\n",
       "  \"contains(('cities', 'http'))\": False,\n",
       "  \"contains(('claim', 'united'))\": False,\n",
       "  \"contains(('co', '3fq3XElbOn'))\": False,\n",
       "  \"contains(('co', 'F2LFULCbQ7'))\": False,\n",
       "  \"contains(('co', 'rfXlV1kGDh'))\": False,\n",
       "  \"contains(('cold', 'weather'))\": False,\n",
       "  \"contains(('coming', 'back'))\": False,\n",
       "  \"contains(('cool', 'SouthwestAir'))\": False,\n",
       "  \"contains(('cool', 'cities'))\": False,\n",
       "  \"contains(('cool', 'united'))\": False,\n",
       "  \"contains(('could', 'fly'))\": False,\n",
       "  \"contains(('counter', 'united'))\": False,\n",
       "  \"contains(('credit', 'united'))\": False,\n",
       "  \"contains(('crew', 'She'))\": False,\n",
       "  \"contains(('currently', 'using'))\": False,\n",
       "  \"contains(('customers', 'get'))\": False,\n",
       "  \"contains(('day', 'amp'))\": False,\n",
       "  \"contains(('delay', 'due'))\": False,\n",
       "  \"contains(('delays', 'Cancelled'))\": False,\n",
       "  \"contains(('different', 'airline'))\": False,\n",
       "  \"contains(('different', 'flights'))\": False,\n",
       "  \"contains(('direct', 'message'))\": False,\n",
       "  \"contains(('disappointed', 'VirginAmerica'))\": False,\n",
       "  \"contains(('done', 'JetBlue'))\": False,\n",
       "  \"contains(('embossed', 'badges'))\": False,\n",
       "  \"contains(('en', 'route'))\": False,\n",
       "  \"contains(('enquires', 'email'))\": False,\n",
       "  \"contains(('entertainment', 'system'))\": False,\n",
       "  \"contains(('entire', 'day'))\": False,\n",
       "  \"contains(('etc', 'united'))\": False,\n",
       "  \"contains(('even', 'know'))\": False,\n",
       "  \"contains(('evening', 'SouthwestAir'))\": False,\n",
       "  \"contains(('ever', 'SouthwestAir'))\": False,\n",
       "  \"contains(('ever', 'experienced'))\": False,\n",
       "  \"contains(('every', 'day'))\": False,\n",
       "  \"contains(('excellent', 'service'))\": False,\n",
       "  \"contains(('experience', 'united'))\": False,\n",
       "  \"contains(('fail', 'united'))\": False,\n",
       "  \"contains(('far', 'away'))\": False,\n",
       "  \"contains(('finally', 'made'))\": False,\n",
       "  \"contains(('first', 'leg'))\": False,\n",
       "  \"contains(('first', 'trip'))\": False,\n",
       "  \"contains(('flight', 'If'))\": False,\n",
       "  \"contains(('flight', 'It'))\": False,\n",
       "  \"contains(('flight', 'booked'))\": False,\n",
       "  \"contains(('flight', 'leaves'))\": False,\n",
       "  \"contains(('flight', 'leaving'))\": False,\n",
       "  \"contains(('flight', 'reservation'))\": False,\n",
       "  \"contains(('flight', 'staff'))\": False,\n",
       "  \"contains(('flights', 'going'))\": False,\n",
       "  \"contains(('fly', 'home'))\": False,\n",
       "  \"contains(('free', 'flights'))\": False,\n",
       "  \"contains(('frustrated', 'united'))\": False,\n",
       "  \"contains(('full', 'day'))\": False,\n",
       "  \"contains(('full', 'refund'))\": False,\n",
       "  \"contains(('general', 'enquires'))\": False,\n",
       "  \"contains(('get', 'Cancelled'))\": False,\n",
       "  \"contains(('get', 'reimbursed'))\": False,\n",
       "  \"contains(('get', 'stuck'))\": False,\n",
       "  \"contains(('getaway', 'deals'))\": False,\n",
       "  \"contains(('go', 'home'))\": False,\n",
       "  \"contains(('good', 'day'))\": False,\n",
       "  \"contains(('good', 'luck'))\": False,\n",
       "  \"contains(('good', 'morning'))\": False,\n",
       "  \"contains(('got', 'thru'))\": False,\n",
       "  \"contains(('great', 'JetBlue'))\": False,\n",
       "  \"contains(('great', 'SouthwestAir'))\": False,\n",
       "  \"contains(('great', 'Thank'))\": False,\n",
       "  \"contains(('great', 'news'))\": False,\n",
       "  \"contains(('great', 'trip'))\": False,\n",
       "  \"contains(('happened', 'united'))\": False,\n",
       "  \"contains(('hard', 'work'))\": False,\n",
       "  \"contains(('hear', 'back'))\": False,\n",
       "  \"contains(('heard', 'back'))\": False,\n",
       "  \"contains(('hi', 'guys'))\": False,\n",
       "  \"contains(('high', 'five'))\": False,\n",
       "  \"contains(('home', 'SouthwestAir'))\": False,\n",
       "  \"contains(('hour', 'delayed'))\": False,\n",
       "  \"contains(('hour', 'united'))\": False,\n",
       "  \"contains(('hours', 'AmericanAir'))\": False,\n",
       "  \"contains(('huge', 'fan'))\": False,\n",
       "  \"contains(('information', 'united'))\": False,\n",
       "  \"contains(('issue', 'united'))\": False,\n",
       "  \"contains(('kids', 'need'))\": False,\n",
       "  \"contains(('known', 'traveler'))\": False,\n",
       "  \"contains(('left', 'united'))\": False,\n",
       "  \"contains(('lost', 'baggage'))\": False,\n",
       "  \"contains(('lost', 'item'))\": False,\n",
       "  \"contains(('lost', 'luggage'))\": False,\n",
       "  \"contains(('lost', 'united'))\": False,\n",
       "  \"contains(('love', 'http'))\": False,\n",
       "  \"contains(('maintenance', 'issue'))\": False,\n",
       "  \"contains(('marketing', 'song'))\": False,\n",
       "  \"contains(('meal', 'voucher'))\": False,\n",
       "  \"contains(('mechanical', 'delay'))\": False,\n",
       "  \"contains(('mechanical', 'failure'))\": False,\n",
       "  \"contains(('media', 'team'))\": False,\n",
       "  \"contains(('min', 'wait'))\": False,\n",
       "  \"contains(('minutes', 'early'))\": False,\n",
       "  \"contains(('missed', 'connections'))\": False,\n",
       "  \"contains(('month', 'ago'))\": False,\n",
       "  \"contains(('much', 'better'))\": False,\n",
       "  \"contains(('name', 'united'))\": False,\n",
       "  \"contains(('new', 'one'))\": False,\n",
       "  \"contains(('new', 'seats'))\": False,\n",
       "  \"contains(('next', 'day'))\": False,\n",
       "  \"contains(('night', 'united'))\": False,\n",
       "  \"contains(('number', 'SouthwestAir'))\": False,\n",
       "  \"contains(('ok', 'united'))\": False,\n",
       "  \"contains(('one', 'knows'))\": False,\n",
       "  \"contains(('one', 'united'))\": False,\n",
       "  \"contains(('origin', 'destination'))\": False,\n",
       "  \"contains(('overhead', 'bin'))\": False,\n",
       "  \"contains(('overhead', 'space'))\": False,\n",
       "  \"contains(('past', 'week'))\": False,\n",
       "  \"contains(('patches', 'superior'))\": False,\n",
       "  \"contains(('people', 'united'))\": False,\n",
       "  \"contains(('person', 'working'))\": False,\n",
       "  \"contains(('plane', 'AmericanAir'))\": False,\n",
       "  \"contains(('plane', 'ticket'))\": False,\n",
       "  ...},\n",
       " 'positive')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#applying the function to our documents\n",
    "featuresets2 = [(bi_document_features(d, bigram_features), c) for (d, c) in docs]\n",
    "\n",
    "#seeing the featureset for the first document\n",
    "featuresets2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "03c8849b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8456"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking the length of the featureset\n",
    "#it should be the same than unigram, because we processed number of documents\n",
    "#this is for verification\n",
    "len(featuresets2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6c3a23bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#how we run the classifier to see if we get a good accuracy score\n",
    "#all this is just to find out which feature is more informative to predict sentiment\n",
    "#Naive Bayes classifier with 5-fold cross validation for training on sentiments using bigram features\n",
    "\n",
    "kf = KFold(n_splits = 5)\n",
    "sum = 0\n",
    "\n",
    "for train, test in kf.split(featuresets2):\n",
    "    train_data2 = np.array(featuresets2)[train]\n",
    "    test_data2 = np.array(featuresets2)[test]\n",
    "    classifier2 = nltk.NaiveBayesClassifier.train(train_data2)\n",
    "    sum += nltk.classify.accuracy(classifier2, test_data2)\n",
    "\n",
    "acc2 = sum/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4e6544d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5774611942239055"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#accuracy of classifier2, bigrams\n",
    "\n",
    "acc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cb8f3d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since the accuracy for unigrams is higher than bigrams, we'll use unigrams\n",
    "#as a feature to train the classifier and pass the test set through it\n",
    "#the test set is the negative review dataset, whose reviews we want to predict sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "280dacd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determining the sentiments of the 1/4th of the comments using classifier1\n",
    "# for debugging purposes, we use only 1/100 of the corpus\n",
    "# but for the final experiment you should use at least 1/4 of it\n",
    "# NOTE: WITH 1/4 OF THE SAMPLE THIS CODE TAKES 2 HOURS TO RUN\n",
    "\n",
    "#creating emply lists to append the tweets to\n",
    "pos_sent = []\n",
    "neg_sent = []\n",
    "neu_sent = []\n",
    "\n",
    "    \n",
    "#and total values of positive, negative or neutral tweets\n",
    "#all these lists will end up as columns in our csv file, created later on\n",
    "total_pos = []\n",
    "total_neg = []\n",
    "total_neu = []\n",
    "    \n",
    "#iterating over the test file of tweets we crated at the very beginning of the notebook\n",
    "#PLEASE EDIT THE NUMBER OF DOCUMENTS AS MENTIONED ABOVE\n",
    "for i in range(0, int(len(test_set['Responses:'])/100)):\n",
    "    #extracting the text\n",
    "    sentences = nltk.sent_tokenize(test_set['Responses:'][i])\n",
    "    #opening the counter to add up positive, negative, or neutral according to predicted labels\n",
    "    pos_count = 0\n",
    "    neg_count = 0\n",
    "    neu_count = 0\n",
    "    #using our first classifier, the one trained with unigram features\n",
    "    for sents in sentences:\n",
    "        senti = classifier.classify(document_features(nltk.word_tokenize(sents), word_features))\n",
    "        #adding items to the counter as they are classified\n",
    "        if senti == 'positive':\n",
    "            pos_sent.append(sents)\n",
    "            pos_count += 1\n",
    "    \n",
    "        elif senti == 'negative':\n",
    "            neg_sent.append(sents)\n",
    "            neg_count += 1\n",
    "    \n",
    "        else:\n",
    "            neu_sent.append(sents)\n",
    "            neu_count += 1\n",
    "    #appending the totals\n",
    "    total_pos.append(pos_count)\n",
    "    total_neg.append(neg_count)\n",
    "    total_neu.append(neu_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cfedd558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#how many positive sentiment sentences did we predict?\n",
    "len(pos_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "962aefe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#and how many negative sentiment ones?\n",
    "len(neg_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "18e0e057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#what about neutral?\n",
    "len(neu_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b82eac5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#WE ARE DONE WITH PREDICTIONS\n",
    "#WE WILL ZOOM IN ON INFORMATIVE FEATURES ACCORDING TO PART OF SPEECH TAGS\n",
    "#FOCUSING ON ADJECTIVES, ADVERBS, NOUNS AND VERBS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ed486af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We tokenize and attach POS to each sentence in the Positive Sentences list\n",
    "\n",
    "tokens_pos = [nltk.word_tokenize(sent) for sent in pos_sent]\n",
    "tags_pos = [nltk.pos_tag(token) for token in tokens_pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1a780dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#same for Negative Sentences\n",
    "\n",
    "tokens_neg = [nltk.word_tokenize(sent) for sent in neg_sent]\n",
    "tags_neg = [nltk.pos_tag(token) for token in tokens_neg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "adc6dc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#same for Neutral Sentences\n",
    "\n",
    "tokens_neu = [nltk.word_tokenize(sent) for sent in neu_sent]\n",
    "tags_neu = [nltk.pos_tag(token) for token in tokens_neu]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4de686d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('This', 'DT'), ('has', 'VBZ'), ('a', 'DT'), ('significant', 'JJ'), ('proportion', 'NN'), ('of', 'IN'), ('sherry', 'NN'), ('wood', 'NN'), ('and', 'CC'), ('it', 'PRP'), ('marks', 'VBZ'), ('a', 'DT'), ('real', 'JJ'), ('step', 'NN'), ('up', 'RB'), ('from', 'IN'), ('its', 'PRP$'), ('younger', 'JJR'), ('stablemates', 'NNS'), ('.', '.')]]\n"
     ]
    }
   ],
   "source": [
    "#let's check that everything is okay. We print the first 3 Negative sentences\n",
    "print(tags_neg[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a86e63c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('The', 'DT'), ('nose', 'JJ'), ('offers', 'NNS'), ('sultanas', 'NNS'), (',', ','), ('raisins', 'NNS'), (',', ','), ('and', 'CC'), ('hot', 'JJ'), ('chocolate', 'NN'), ('.', '.')], [('Developing', 'VBG'), ('vanilla', 'NN'), ('and', 'CC'), ('a', 'DT'), ('hint', 'NN'), ('of', 'IN'), ('over-ripe', 'JJ'), ('bananas', 'NNS'), ('.', '.')], [('Finally', 'RB'), (',', ','), ('burnt', 'NN'), ('sugar', 'NN'), ('and', 'CC'), ('caramel', 'NN'), ('.', '.')]]\n"
     ]
    }
   ],
   "source": [
    "#what about the first 3 positive ones...\n",
    "print(tags_pos[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6eafe7b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('Single', 'NNP'), ('cask', 'NN'), ('Aberfeldy', 'NNP'), ('bottlings', 'NNS'), ('are', 'VBP'), ('very', 'RB'), ('few', 'JJ'), ('and', 'CC'), ('far', 'RB'), ('between', 'IN'), (',', ','), ('and', 'CC'), ('this', 'DT'), ('is', 'VBZ'), ('a', 'DT'), ('stunner', 'NN'), ('!', '.')], [('After', 'IN'), ('hogshead', 'JJ'), ('maturation', 'NN'), ('the', 'DT'), ('whisky', 'NN'), ('ultimately', 'RB'), ('underwent', 'JJ'), ('a', 'DT'), ('period', 'NN'), ('of', 'IN'), ('finishing', 'VBG'), ('in', 'IN'), ('an', 'DT'), ('ex-sherry', 'JJ'), ('cask', 'NN'), ('prior', 'RB'), ('to', 'TO'), ('bottling', 'VBG'), ('.', '.')], [('The', 'DT'), ('fruit', 'NN'), ('is', 'VBZ'), ('balanced', 'VBN'), ('by', 'IN'), ('honeyed', 'JJ'), ('malt', 'NN'), ('and', 'CC'), ('light', 'JJ'), ('caramel', 'NN'), ('.', '.')]]\n"
     ]
    }
   ],
   "source": [
    "#let's check that everything is okay. We print the first 3 Neutral sentences\n",
    "print(tags_neu[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f8c83aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATING FUNCTIONS TO REUSE CODE FOR RETRIEVING DIFFERENTE TYPES OF PHRASES\n",
    "\n",
    "# We will apply this code to find ADJECTIVE PHRASES positive and negative sentences first\n",
    "# after that, you will need to change the grammar and subtree label in the function to extract:\n",
    "# ADVERB, NOUN, and VERB phrases, as stated in the Homework guidelines\n",
    "\n",
    "# EXTRACTING ACCORDING TO A GRAMMAR ADJECTIVE PHRASES\n",
    "# this is the code we reuse, passing the \\\"tags_pos\\\", \\\"tags_neg\\\" or \\\"tags_neu\\\" accordingly\n",
    "def grammar_phrases(tags_sent):\n",
    "    grammar_adjph = \"ADJPH: {<RB.?>+<JJ.?>}\" # REMEMBER TO EDI THIS GRAMMAR FOR ADVERBS & VERBS!\n",
    "    chunk_parser_adj = nltk.RegexpParser(grammar_adjph)\n",
    "    adjph_tags = []\n",
    "    for sent in tags_sent:\n",
    "        if len(sent) > 0:\n",
    "            tree = chunk_parser_adj.parse(sent)\n",
    "            for subtree in tree.subtrees():\n",
    "                if subtree.label() == 'ADJPH': # THIS ALSO NEEDS EDITION FOR ADVERBS & VERBS\n",
    "                    adjph_tags.append(subtree)\n",
    "            return adjph_tags\n",
    "\n",
    "# EXTRACTING ADJECTIVE PHRASES without POS tags, just the phrase\n",
    "# we also reuse this but replacing the 'tagged_phrase' in each new case\n",
    "def word_phrase(tagged_phrase):\n",
    "    adjective_phrases = []\n",
    "    for sent in tagged_phrase:\n",
    "        temp = ''\n",
    "        for w, t in sent:\n",
    "            temp += w+ ' '\n",
    "        adjective_phrases.append(temp)\n",
    "    return adjective_phrases\n",
    "\n",
    "# RANKING BY FREQUENCY\n",
    "# this is also a function to reuse\n",
    "def get_frequency(phrases):\n",
    "    phrases_frequency = nltk.FreqDist(phrases)\n",
    "    return phrases_frequency.most_common(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "68dce1b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjective phrases in positive sentences, with POS:  []\n"
     ]
    }
   ],
   "source": [
    "# EXTRACTING POSITIVE PHRASES AND THEIR POS\n",
    "adjph_pos = grammar_phrases(tags_pos)\n",
    "print('Adjective phrases in positive sentences, with POS: ', adjph_pos[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2dbc2d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjective phrases in negative sentences, with POS:  []\n"
     ]
    }
   ],
   "source": [
    "# EXTRACTING Negative PHRASES AND THEIR POS\n",
    "adjph_neg = grammar_phrases(tags_neg)\n",
    "print('Adjective phrases in negative sentences, with POS: ', adjph_neg[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9c135768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjective phrases in neutral sentences, with POS:  [Tree('ADJPH', [('very', 'RB'), ('few', 'JJ')])]\n"
     ]
    }
   ],
   "source": [
    "# EXTRACTING NeutralPHRASES AND THEIR POS\n",
    "adjph_neu = grammar_phrases(tags_neu)\n",
    "print('Adjective phrases in neutral sentences, with POS: ', adjph_neu[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9205056a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 adjective phrases in positive sentences:  []\n"
     ]
    }
   ],
   "source": [
    "# EXTRACTING POSITIVE ADJECTIVE PHRASES (WORDS ONLY)\n",
    "word_adjph_pos = word_phrase(adjph_pos)\n",
    "print('First 10 adjective phrases in positive sentences: ', word_adjph_pos[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ea9f0520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 adjective phrases in negative sentences:  []\n"
     ]
    }
   ],
   "source": [
    "# EXTRACTING Negative ADJECTIVE PHRASES (WORDS ONLY)\n",
    "word_adjph_neg = word_phrase(adjph_neg)\n",
    "print('First 10 adjective phrases in negative sentences: ', word_adjph_neg[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "50bd8679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 adjective phrases in neutral sentences:  ['very few ']\n"
     ]
    }
   ],
   "source": [
    "# EXTRACTING Neutral ADJECTIVE PHRASES (WORDS ONLY)\n",
    "word_adjph_neu = word_phrase(adjph_neu)\n",
    "print('First 10 adjective phrases in neutral sentences: ', word_adjph_neu[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a3ac2966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 50 adjective phrases in positive sentences:  []\n"
     ]
    }
   ],
   "source": [
    "# RANKING POSITIVE PHRASES BY FREQUENCY\n",
    "most_common_adjph_pos = get_frequency(word_adjph_pos)\n",
    "print(\"Top 50 adjective phrases in positive sentences: \", most_common_adjph_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "def9fec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 50 adjective phrases in negative sentences:  []\n"
     ]
    }
   ],
   "source": [
    "# RANKING Negative PHRASES BY FREQUENCY\n",
    "most_common_adjph_neg = get_frequency(word_adjph_neg)\n",
    "print(\"Top 50 adjective phrases in negative sentences: \", most_common_adjph_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "00f5b9e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 50 adjective phrases in neutral sentences:  [('very few ', 1)]\n"
     ]
    }
   ],
   "source": [
    "# RANKING Neutral PHRASES BY FREQUENCY\n",
    "most_common_adjph_neu = get_frequency(word_adjph_neu)\n",
    "print(\"Top 50 adjective phrases in neutral sentences: \", most_common_adjph_neu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8093a7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOW, YOUR TURN!!\n",
    "# USE THESE FUNCTIONS TO EXTRACT NEGATIVE PHRASES, CLEAN NEGATIVE ADJECTIVE PHRASES FROM POS,\n",
    "# AND RANK NEGATIVE PHRASES BY FREQUENCY\n",
    "\n",
    "# YOU ALSO NEED TO MODIFY THE GRAMMAR TO LOOK FOR:\n",
    "# NOUNS\n",
    "# VERBS\n",
    "# IN BOTH CASES, DON'T FORGET THAT THERE ARE MANY TAGS IN EACH GROUP!!\n",
    "#  CHECK THE PENN POS TAGS LIST: https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "332ed863",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we are ready to start preparing our csv file\n",
    "#we first create a table using a pandas' dataframe\n",
    "#to assign columns for the information extracted from each tweet\n",
    "#namely title, author and country, along with and number of sentences stores before in our lists\n",
    "\n",
    "df = pd.DataFrame(list(zip(total_pos, total_neg, total_neu)),\n",
    "columns = ['n_pos_sents', 'n_neg_sents', 'n_neu_sents'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "67685e87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_pos_sents</th>\n",
       "      <th>n_neg_sents</th>\n",
       "      <th>n_neu_sents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_pos_sents  n_neg_sents  n_neu_sents\n",
       "0             6            0            2\n",
       "1             6            0            2\n",
       "2             3            0            2\n",
       "3             5            0            4\n",
       "4             5            0            0\n",
       "5             6            0            0\n",
       "6             3            0            2\n",
       "7             5            0            1\n",
       "8             4            0            1\n",
       "9             4            0            1\n",
       "10            4            0            1\n",
       "11            4            0            1\n",
       "12            2            0            2\n",
       "13            3            0            1\n",
       "14            2            1            1"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#printing the dataframe, to confirm everything is fine\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "090c0bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we now finally save our table in a csv file\n",
    "\n",
    "df.to_csv('C:\\\\Users\\\\HP\\\\OneDrive\\\\Desktop\\\\Grad School\\\\IST718 Big Data\\\\my_scotchfilereviews_classified.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "395424f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The nose offers sultanas, raisins, and hot chocolate.',\n",
       " 'Developing vanilla and a hint of over-ripe bananas.',\n",
       " 'Finally, burnt sugar and caramel.']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking some of the ouptut: the first three sentences labeled as positive\n",
    "pos_sent[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "16d28e0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This has a significant proportion of sherry wood and it marks a real step up from its younger stablemates.']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now the first 3 sentences labeled as negative\n",
    "neg_sent[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "06c3480d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Single cask Aberfeldy bottlings are very few and far between, and this is a stunner!',\n",
       " 'After hogshead maturation the whisky ultimately underwent a period of finishing in an ex-sherry cask prior to bottling.',\n",
       " 'The fruit is balanced by honeyed malt and light caramel.']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#and finally the neutral ones\n",
    "neu_sent[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "aec6b63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PLEASE OPEN THE NEWLY CREATED CSV FILE TO CHECK EVERYTHING IS FINE\n",
    "#DO NOT FORGET TO EXPLAIN THE OUTPUTS IN YOUR REPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ad3cf2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will apply this code to find Adverb PHRASES positive and negative sentences first\n",
    "\n",
    "\n",
    "# EXTRACTING ACCORDING TO A GRAMMAR Adverb PHRASES\n",
    "# this is the code we reuse, passing the \\\"tags_pos\\\", \\\"tags_neg\\\" or \\\"tags_neu\\\" accordingly\n",
    "def grammar_phrases(tags_sent):\n",
    "    grammar_advph = \"ADVPH: {<RB>+<RB>}\"\n",
    "    chunk_parser_adv = nltk.RegexpParser(grammar_advph)\n",
    "    advph_tags = []\n",
    "    for sent in tags_sent:\n",
    "        if len(sent) > 0:\n",
    "            tree = chunk_parser_adv.parse(sent)\n",
    "            for subtree in tree.subtrees():\n",
    "                if subtree.label() == 'ADVPH': # THIS ALSO NEEDS EDITION FOR ADVERBS & VERBS\n",
    "                    advph_tags.append(subtree)\n",
    "            return advph_tags\n",
    "\n",
    "# EXTRACTING ADJECTIVE PHRASES without POS tags, just the phrase\n",
    "# we also reuse this but replacing the 'tagged_phrase' in each new case\n",
    "def word_phrase(tagged_phrase):\n",
    "    adverb_phrases = []\n",
    "    for sent in tagged_phrase:\n",
    "        temp = ''\n",
    "        for w, t in sent:\n",
    "            temp += w+ ' '\n",
    "        adverb_phrases.append(temp)\n",
    "    return adverb_phrases\n",
    "\n",
    "# RANKING BY FREQUENCY\n",
    "# this is also a function to reuse\n",
    "def get_frequency(phrases):\n",
    "    phrases_frequency = nltk.FreqDist(phrases)\n",
    "    return phrases_frequency.most_common(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "08b1e3bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adverb phrases in positive sentences, with POS:  []\n"
     ]
    }
   ],
   "source": [
    "# EXTRACTING POSITIVE PHRASES AND THEIR POS\n",
    "advph_pos = grammar_phrases(tags_pos)\n",
    "print('Adverb phrases in positive sentences, with POS: ', advph_pos[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "493a3dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adverb phrases in negative sentences, with POS:  []\n"
     ]
    }
   ],
   "source": [
    "# EXTRACTING Negative PHRASES AND THEIR POS\n",
    "advph_neg = grammar_phrases(tags_neg)\n",
    "print('Adverb phrases in negative sentences, with POS: ', advph_neg[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9d761d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adverb phrases in neutral sentences, with POS:  []\n"
     ]
    }
   ],
   "source": [
    "# EXTRACTING Neutral PHRASES AND THEIR POS\n",
    "advph_neu = grammar_phrases(tags_neu)\n",
    "print('Adverb phrases in neutral sentences, with POS: ', advph_neu[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "17f53635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 adverb phrases in positive sentences:  []\n"
     ]
    }
   ],
   "source": [
    "# EXTRACTING POSITIVE Adverb PHRASES (WORDS ONLY)\n",
    "word_advph_pos = word_phrase(advph_pos)\n",
    "print('First 10 adverb phrases in positive sentences: ', word_advph_pos[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d53cead2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 adverb phrases in negative sentences:  []\n"
     ]
    }
   ],
   "source": [
    "# EXTRACTING Negative Adverb PHRASES (WORDS ONLY)\n",
    "word_advph_neg = word_phrase(advph_neg)\n",
    "print('First 10 adverb phrases in negative sentences: ', word_advph_neg[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a5185917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 adverb phrases in neutral sentences:  []\n"
     ]
    }
   ],
   "source": [
    "# EXTRACTING Neutral Adverb PHRASES (WORDS ONLY)\n",
    "word_advph_neu = word_phrase(advph_neu)\n",
    "print('First 10 adverb phrases in neutral sentences: ', word_advph_neu[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4d900c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 50 adverb phrases in positive sentences:  []\n"
     ]
    }
   ],
   "source": [
    "# RANKING POSITIVE PHRASES BY FREQUENCY\n",
    "most_common_advph_pos = get_frequency(word_advph_pos)\n",
    "print(\"Top 50 adverb phrases in positive sentences: \", most_common_advph_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3ece9aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 50 adverb phrases in neg sentences:  []\n"
     ]
    }
   ],
   "source": [
    "# RANKING Negative PHRASES BY FREQUENCY\n",
    "most_common_advph_neg = get_frequency(word_advph_neg)\n",
    "print(\"Top 50 adverb phrases in neg sentences: \", most_common_advph_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "95fdb3e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 50 adverb phrases in neu sentences:  []\n"
     ]
    }
   ],
   "source": [
    "# RANKING Neutral PHRASES BY FREQUENCY\n",
    "most_common_advph_neu = get_frequency(word_advph_neu)\n",
    "print(\"Top 50 adverb phrases in neu sentences: \", most_common_advph_neu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a719a618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will apply this code to find verb PHRASES positive and negative sentences first\n",
    "\n",
    "\n",
    "# EXTRACTING ACCORDING TO A GRAMMAR VERB PHRASES\n",
    "# this is the code we reuse, passing the \\\"tags_pos\\\", \\\"tags_neg\\\" or \\\"tags_neu\\\" accordingly\n",
    "def grammar_phrases(tags_sent):\n",
    "    grammar_verb = \"VERB: {<VB>+<VB>}\" \n",
    "    chunk_parser_verb = nltk.RegexpParser(grammar_verb)\n",
    "    verb_tags = []\n",
    "    for sent in tags_sent:\n",
    "        if len(sent) > 0:\n",
    "            tree = chunk_parser_verb.parse(sent)\n",
    "            for subtree in tree.subtrees():\n",
    "                if subtree.label() == 'VERB': \n",
    "                    verb_tags.append(subtree)\n",
    "            return verb_tags\n",
    "\n",
    "# EXTRACTING Verb PHRASES without POS tags, just the phrase\n",
    "# we also reuse this but replacing the 'tagged_phrase' in each new case\n",
    "def word_phrase(tagged_phrase):\n",
    "    verb_phrases = []\n",
    "    for sent in tagged_phrase:\n",
    "        temp = ''\n",
    "        for w, t in sent:\n",
    "            temp += w+ ' '\n",
    "        verb_phrases.append(temp)\n",
    "    return verb_phrases\n",
    "\n",
    "# RANKING BY FREQUENCY\n",
    "# this is also a function to reuse\n",
    "def get_frequency(phrases):\n",
    "    phrases_frequency = nltk.FreqDist(phrases)\n",
    "    return phrases_frequency.most_common(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "82640289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verb phrases in positive sentences, with POS:  []\n"
     ]
    }
   ],
   "source": [
    "# EXTRACTING POSITIVE PHRASES AND THEIR POS\n",
    "verb_pos = grammar_phrases(tags_pos)\n",
    "print('Verb phrases in positive sentences, with POS: ', verb_pos[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "08f42ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verb phrases in negative sentences, with POS:  []\n"
     ]
    }
   ],
   "source": [
    "# EXTRACTING Negative PHRASES AND THEIR POS\n",
    "verb_neg = grammar_phrases(tags_neg)\n",
    "print('Verb phrases in negative sentences, with POS: ', verb_neg[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2d68142f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verb phrases in neutral sentences, with POS:  []\n"
     ]
    }
   ],
   "source": [
    "# EXTRACTING Neutral PHRASES AND THEIR POS\n",
    "verb_neu = grammar_phrases(tags_neu)\n",
    "print('Verb phrases in neutral sentences, with POS: ', verb_neu[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "859a9d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 verb phrases in positive sentences:  []\n"
     ]
    }
   ],
   "source": [
    "# EXTRACTING POSITIVE verb PHRASES (WORDS ONLY)\n",
    "word_verb_pos = word_phrase(verb_pos)\n",
    "print('First 10 verb phrases in positive sentences: ', word_verb_pos[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "dc52bbfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 verb phrases in negative sentences:  []\n"
     ]
    }
   ],
   "source": [
    "# EXTRACTING Negative verb PHRASES (WORDS ONLY)\n",
    "word_verb_neg = word_phrase(verb_neg)\n",
    "print('First 10 verb phrases in negative sentences: ', word_verb_neg[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "063ed379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 verb phrases in neutral sentences:  []\n"
     ]
    }
   ],
   "source": [
    "# EXTRACTING Neutral verb PHRASES (WORDS ONLY)\n",
    "word_verb_neu = word_phrase(verb_neu)\n",
    "print('First 10 verb phrases in neutral sentences: ', word_verb_neu[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "83b29c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 50 verb phrases in positive sentences:  []\n"
     ]
    }
   ],
   "source": [
    "# RANKING POSITIVE PHRASES BY FREQUENCY\n",
    "most_common_verb_pos = get_frequency(word_verb_pos)\n",
    "print(\"Top 50 verb phrases in positive sentences: \", most_common_verb_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f854d5ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 50 verb phrases in neg sentences:  []\n"
     ]
    }
   ],
   "source": [
    "# RANKING Negative PHRASES BY FREQUENCY\n",
    "most_common_verb_neg = get_frequency(word_verb_neg)\n",
    "print(\"Top 50 verb phrases in neg sentences: \", most_common_verb_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3070d998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 50 verb phrases in neu sentences:  []\n"
     ]
    }
   ],
   "source": [
    "# RANKING Neutral PHRASES BY FREQUENCY\n",
    "most_common_verb_neu = get_frequency(word_verb_neu)\n",
    "print(\"Top 50 verb phrases in neu sentences: \", most_common_verb_neu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c268869b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will apply this code to find verb PHRASES positive and negative sentences first\n",
    "\n",
    "\n",
    "# EXTRACTING ACCORDING TO A GRAMMAR NOUN PHRASES\n",
    "# this is the code we reuse, passing the \\\"tags_pos\\\", \\\"tags_neg\\\" or \\\"tags_neu\\\" accordingly\n",
    "def grammar_phrases(tags_sent):\n",
    "    grammar_noun = \"NOUN: {<NN>+<NN>}\" \n",
    "    chunk_parser_noun = nltk.RegexpParser(grammar_noun)\n",
    "    noun_tags = []\n",
    "    for sent in tags_sent:\n",
    "        if len(sent) > 0:\n",
    "            tree = chunk_parser_noun.parse(sent)\n",
    "            for subtree in tree.subtrees():\n",
    "                if subtree.label() == 'NOUN': \n",
    "                    noun_tags.append(subtree)\n",
    "            return noun_tags\n",
    "\n",
    "# EXTRACTING NOUN PHRASES without POS tags, just the phrase\n",
    "# we also reuse this but replacing the 'tagged_phrase' in each new case\n",
    "def word_phrase(tagged_phrase):\n",
    "    noun_phrases = []\n",
    "    for sent in tagged_phrase:\n",
    "        temp = ''\n",
    "        for w, t in sent:\n",
    "            temp += w+ ' '\n",
    "        noun_phrases.append(temp)\n",
    "    return noun_phrases\n",
    "\n",
    "# RANKING BY FREQUENCY\n",
    "# this is also a function to reuse\n",
    "def get_frequency(phrases):\n",
    "    phrases_frequency = nltk.FreqDist(phrases)\n",
    "    return phrases_frequency.most_common(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "988d8ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noun phrases in positive sentences, with POS:  []\n"
     ]
    }
   ],
   "source": [
    "# EXTRACTING POSITIVE PHRASES AND THEIR POS\n",
    "noun_pos = grammar_phrases(tags_pos)\n",
    "print('Noun phrases in positive sentences, with POS: ', noun_pos[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ca61e44e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noun phrases in negative sentences, with POS:  [Tree('NOUN', [('sherry', 'NN'), ('wood', 'NN')])]\n"
     ]
    }
   ],
   "source": [
    "# EXTRACTING Negative PHRASES AND THEIR POS\n",
    "noun_neg = grammar_phrases(tags_neg)\n",
    "print('Noun phrases in negative sentences, with POS: ', noun_neg[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5dcd1ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noun phrases in neutral sentences, with POS:  []\n"
     ]
    }
   ],
   "source": [
    "# EXTRACTING Neutral PHRASES AND THEIR POS\n",
    "noun_neu = grammar_phrases(tags_neu)\n",
    "print('Noun phrases in neutral sentences, with POS: ', noun_neu[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a92ab9f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 noun phrases in positive sentences:  []\n"
     ]
    }
   ],
   "source": [
    "# EXTRACTING POSITIVE noun PHRASES (WORDS ONLY)\n",
    "word_noun_pos = word_phrase(noun_pos)\n",
    "print('First 10 noun phrases in positive sentences: ', word_noun_pos[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "11b7c49a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 noun phrases in negative sentences:  ['sherry wood ']\n"
     ]
    }
   ],
   "source": [
    "# EXTRACTING Negative noun PHRASES (WORDS ONLY)\n",
    "word_noun_neg = word_phrase(noun_neg)\n",
    "print('First 10 noun phrases in negative sentences: ', word_noun_neg[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "299a356c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 noun phrases in neutral sentences:  []\n"
     ]
    }
   ],
   "source": [
    "# EXTRACTING Neutral noun PHRASES (WORDS ONLY)\n",
    "word_noun_neu = word_phrase(noun_neu)\n",
    "print('First 10 noun phrases in neutral sentences: ', word_noun_neu[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f4b7d98e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 50 noun phrases in positive sentences:  []\n"
     ]
    }
   ],
   "source": [
    "# RANKING POSITIVE PHRASES BY FREQUENCY\n",
    "most_common_noun_pos = get_frequency(word_noun_pos)\n",
    "print(\"Top 50 noun phrases in positive sentences: \", most_common_noun_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "20804c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 50 noun phrases in neg sentences:  [('sherry wood ', 1)]\n"
     ]
    }
   ],
   "source": [
    "# RANKING Negative PHRASES BY FREQUENCY\n",
    "most_common_noun_neg = get_frequency(word_noun_neg)\n",
    "print(\"Top 50 noun phrases in neg sentences: \", most_common_noun_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "67c0d264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 50 noun phrases in neu sentences:  []\n"
     ]
    }
   ],
   "source": [
    "# RANKING Neutral PHRASES BY FREQUENCY\n",
    "most_common_noun_neu = get_frequency(word_noun_neu)\n",
    "print(\"Top 50 noun phrases in neu sentences: \", most_common_noun_neu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d395086d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
